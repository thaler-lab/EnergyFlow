{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to EnergyFlow EnergyFlow is a Python package containing a suite of particle physics tools. Originally designed to compute Energy Flow Polynomials (EFPs), as of version 0.10.0 the package expanded to include implementations of Energy Flow Networks (EFNs) and Particle Flow Networks (PFNs). As of version 0.11.0 , functions for facilitating the computation of the Energy Mover's Distance (EMD) on particle physics events are included. To summarize the main features: Energy Flow Polynomials : EFPs are a collection of jet substructure observables which form a complete linear basis of IRC-safe observables. EnergyFlow provides tools to compute EFPs on events for several energy and angular measures as well as custom measures. Energy Flow Networks : EFNs are infrared- and collinear-safe models designed for learning from collider events as unordered, variable-length sets of particles. EnergyFlow contains customizable Keras implementations of EFNs. Particle Flow Networks : PFNs are general models designed for learning from collider events as unordered, variable-length sets of particles, based on the Deep Sets framework. EnergyFlow contains customizable Keras implementations of PFNs. Energy Mover's Distance : The EMD is a common metric between probability distributions that has been adapted for use as a metric between collider events. EnergyFlow contains code to facilitate the computation of the EMD between events based on an underlying implementation provided by the Python Optimal Transport (POT) library. Beyond the primary functions described above, the EnergyFlow package also provides useful supplementary features. These include a large quark/gluon jet dataset, implementations of additional machine learning architectures useful for collider physics, and many examples exhibiting the usage of the package. Jet Tagging Datasets : A dataset of 2 million simulated quark and gluon jets is provided. Additional Architectures : Implementations of other architectures useful for particle physics are also provided, such as convolutional neural networks (CNNs) for jet images. Detailed Examples : Examples showcasing EFPs, EFNs, PFNs, EMDs, and more. Also see the demos . The current version is 0.12.0 . Changes are summarized in the Release Notes . Using the most up-to-date version is recommended. As of version 0.7.0 , tests have been written covering the majority of the EFP and EMD code. The architectures code is currently tested by running the examples. The source code can be found on GitHub . Get started by installing EnergyFlow , exploring the demos , and running the examples ! References [1] P. T. Komiske, E. M. Metodiev, and J. Thaler, Energy Flow Polynomials: A complete linear basis for jet substructure , JHEP 04 (2018) 013 [ 1712.07124 ]. [2] P. T. Komiske, E. M. Metodiev, and J. Thaler, Energy Flow Networks: Deep Sets for Particle Jets , JHEP 01 (2019) 121 [ 1810.05165 ]. [3] P. T. Komiske, E. M. Metodiev, and J. Thaler, The Metric Space of Collider Events , 1902.02346 . Copyright See the LICENSE for detailed copyright information. EnergyFlow uses a customized einsumfunc.py from the NumPy GitHub repository as well as a few functions relating to downloading files copied from the Keras GitHub repository. The copyrights for these parts of the code are attributed to their respective owners in the LICENSE file.","title":"Home"},{"location":"#welcome-to-energyflow","text":"EnergyFlow is a Python package containing a suite of particle physics tools. Originally designed to compute Energy Flow Polynomials (EFPs), as of version 0.10.0 the package expanded to include implementations of Energy Flow Networks (EFNs) and Particle Flow Networks (PFNs). As of version 0.11.0 , functions for facilitating the computation of the Energy Mover's Distance (EMD) on particle physics events are included. To summarize the main features: Energy Flow Polynomials : EFPs are a collection of jet substructure observables which form a complete linear basis of IRC-safe observables. EnergyFlow provides tools to compute EFPs on events for several energy and angular measures as well as custom measures. Energy Flow Networks : EFNs are infrared- and collinear-safe models designed for learning from collider events as unordered, variable-length sets of particles. EnergyFlow contains customizable Keras implementations of EFNs. Particle Flow Networks : PFNs are general models designed for learning from collider events as unordered, variable-length sets of particles, based on the Deep Sets framework. EnergyFlow contains customizable Keras implementations of PFNs. Energy Mover's Distance : The EMD is a common metric between probability distributions that has been adapted for use as a metric between collider events. EnergyFlow contains code to facilitate the computation of the EMD between events based on an underlying implementation provided by the Python Optimal Transport (POT) library. Beyond the primary functions described above, the EnergyFlow package also provides useful supplementary features. These include a large quark/gluon jet dataset, implementations of additional machine learning architectures useful for collider physics, and many examples exhibiting the usage of the package. Jet Tagging Datasets : A dataset of 2 million simulated quark and gluon jets is provided. Additional Architectures : Implementations of other architectures useful for particle physics are also provided, such as convolutional neural networks (CNNs) for jet images. Detailed Examples : Examples showcasing EFPs, EFNs, PFNs, EMDs, and more. Also see the demos . The current version is 0.12.0 . Changes are summarized in the Release Notes . Using the most up-to-date version is recommended. As of version 0.7.0 , tests have been written covering the majority of the EFP and EMD code. The architectures code is currently tested by running the examples. The source code can be found on GitHub . Get started by installing EnergyFlow , exploring the demos , and running the examples !","title":"Welcome to EnergyFlow"},{"location":"#references","text":"[1] P. T. Komiske, E. M. Metodiev, and J. Thaler, Energy Flow Polynomials: A complete linear basis for jet substructure , JHEP 04 (2018) 013 [ 1712.07124 ]. [2] P. T. Komiske, E. M. Metodiev, and J. Thaler, Energy Flow Networks: Deep Sets for Particle Jets , JHEP 01 (2019) 121 [ 1810.05165 ]. [3] P. T. Komiske, E. M. Metodiev, and J. Thaler, The Metric Space of Collider Events , 1902.02346 .","title":"References"},{"location":"#copyright","text":"See the LICENSE for detailed copyright information. EnergyFlow uses a customized einsumfunc.py from the NumPy GitHub repository as well as a few functions relating to downloading files copied from the Keras GitHub repository. The copyrights for these parts of the code are attributed to their respective owners in the LICENSE file.","title":"Copyright"},{"location":"demos/","text":"Interactive Demos EnergyFlow Demo The EnergyFlow Demo provides an introduction to using EnergyFlow to compute Energy Flow Polynomials. View or download the notebook from GitHub Launch the notebook with Binder EMD Demo The EMD Demo provides an introduction to using EnergyFlow for computing the Energy Mover's Distance (EMD) between jets. View or download the notebook from GitHub Launch the notebook with Binder","title":"Demos"},{"location":"demos/#interactive-demos","text":"","title":"Interactive Demos"},{"location":"demos/#energyflow-demo","text":"The EnergyFlow Demo provides an introduction to using EnergyFlow to compute Energy Flow Polynomials. View or download the notebook from GitHub Launch the notebook with Binder","title":"EnergyFlow Demo"},{"location":"demos/#emd-demo","text":"The EMD Demo provides an introduction to using EnergyFlow for computing the Energy Mover's Distance (EMD) between jets. View or download the notebook from GitHub Launch the notebook with Binder","title":"EMD Demo"},{"location":"examples/","text":"There are currently 5 examples provided for the EnergyFlow package. They currently focus on demonstrating the various architectures included as part of EnergyFlow (see Architectures ). For examples involving the computation of EFPs or EMDs, see the demos . To install the examples to the default directory, ~/.energyflow/examples/ , simply run python -c \"import energyflow; energyflow.utils.get_examples()\" See the get_examples function for more detailed information. efp_example.py An example involving Energy Flow Polynomials (EFPs) and a linear classifier (Fisher's Linear Discriminant by default). First, the EFPSet class is used to compute the EFPs up to the specified dmax , the default being dmax=5 . Then linear classifiers are trained for different numbers of EFPs as input, determined by taking all EFPs up to degree d with d from 1 to dmax . The output of the example is a plot of the ROC curves for the classifiers with different numbers of EFP inputs. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import LinearClassifier from energyflow.datasets import qg_jets from energyflow.utils import data_split, standardize, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 20000 test_frac = 0.2 # efp parameters dmax = 5 measure = 'hadr' beta = 0.5 # plotting colors = ['tab:red', 'tab:orange', 'tab:olive', 'tab:green', 'tab:blue'] ################################################################################ # load data X, y = qg_jets.load(num_data) print('Loaded quark and gluon jets') # calculate EFPs print('Calculating d <= {} EFPs for {} jets... '.format(dmax, num_data), end='') efpset = ef.EFPSet(('d<=', dmax), measure='hadr', beta=beta) masked_X = [x[x[:,0] > 0] for x in X] X = efpset.batch_compute(masked_X) print('Done') # train models with different numbers of EFPs as input rocs = [] for d in range(1, dmax+1): # build architecture model = LinearClassifier(linclass_type='lda') # select EFPs with degree <= d X_d = X[:,efpset.sel(('d<=', d))] # do train/val/test split (X_train, X_test, y_train, y_test) = data_split(X_d, y, val=0, test=test_frac) print('Done train/val/test split') # train model model.fit(X_train, y_train) # get predictions on test data preds = model.predict(X_test) # get ROC curve if we have sklearn if roc_curve: rocs.append(roc_curve(y_test, preds[:,1])) # get area under the ROC curve auc = roc_auc_score(y_test, preds[:,1]) print() print('EFPs d <= {} AUC:'.format(d), auc) print() # make ROC curve plot if we have matplotlib if plt: # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # iterate over the ROC curves and plot them for i,d in enumerate(range(1, dmax+1)): plt.plot(rocs[i][1], 1-rocs[i][0], '-', color=colors[i], label='LDA: d <= {} EFPs'.format(d)) # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show() efn_example.py An example involving Energy Flow Networks (EFNs), which were introduced in 1810.05165 . The EFN class is used to construct the network architecture. The output of the example is a plot of the ROC curves obtained by the EFN as well as the jet mass and constituent multiplicity observables. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import EFN from energyflow.datasets import qg_jets from energyflow.utils import data_split, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################## # the commented values correspond to those in 1810.05165 ############################################################################### # data controls, can go up to 2000000 total for full dataset train, val, test = 75000, 10000, 15000 # train, val, test = 1000000, 200000, 200000 # network architecture parameters Phi_sizes, F_sizes = (100, 100, 128), (100, 100, 100) # Phi_sizes, F_sizes = (100, 100, 256), (100, 100, 100) # network training parameters num_epoch = 5 batch_size = 500 ############################################################################### # load data X, y = qg_jets.load(train + val + test) # ignore pid information X = X[:,:,:3] # convert labels to categorical Y = to_categorical(y, num_classes=2) print('Loaded quark and gluon jets') # preprocess by centering jets and normalizing pts for x in X: mask = x[:,0] > 0 yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0) x[mask,1:3] -= yphi_avg x[mask,0] /= x[:,0].sum() print('Finished preprocessing') # do train/val/test split (z_train, z_val, z_test, p_train, p_val, p_test, Y_train, Y_val, Y_test) = data_split(X[:,:,0], X[:,:,1:], Y, val=val, test=test) print('Done train/val/test split') print('Model summary:') # build architecture efn = EFN(input_dim=2, Phi_sizes=Phi_sizes, F_sizes=F_sizes) # train model efn.fit([z_train, p_train], Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=([z_val, p_val], Y_val), verbose=1) # get predictions on test data preds = efn.predict([z_test, p_test], batch_size=1000) # get ROC curve if we have sklearn if roc_curve: efn_fp, efn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1]) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('EFN AUC:', auc) print() # make ROC curve and filter plot if we have matplotlib if plt: # some nicer plot settings plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True fig, axes = plt.subplots(1, 2, figsize=(8,4)) ######################### ROC Curve Plot ######################### # get multiplicity and mass for comparison masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphims(x).sum(axis=0)) for x in X]) mults = np.asarray([np.count_nonzero(x[:,0]) for x in X]) mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses) mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults) # plot the ROC curves axes[0].plot(efn_tp, 1-efn_fp, '-', color='black', label='EFN') axes[0].plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass') axes[0].plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity') # axes labels axes[0].set_xlabel('Quark Jet Efficiency') axes[0].set_ylabel('Gluon Jet Rejection') # axes limits axes[0].set_xlim(0, 1) axes[0].set_ylim(0, 1) # make legend and show plot axes[0].legend(loc='lower left', frameon=False) ######################### Filter Plot ######################### # plot settings R, n = 0.4, 100 colors = ['Reds', 'Oranges', 'Greens', 'Blues', 'Purples', 'Greys'] grads = np.linspace(0.45, 0.55, 4) # evaluate filters X, Y, Z = efn.eval_filters(R, n=n) # plot filters for i,z in enumerate(Z): axes[1].contourf(X, Y, z/np.max(z), grads, cmap=colors[i%len(colors)]) axes[1].set_xticks(np.linspace(-R, R, 5)) axes[1].set_yticks(np.linspace(-R, R, 5)) axes[1].set_xticklabels(['-R', '-R/2', '0', 'R/2', 'R']) axes[1].set_yticklabels(['-R', '-R/2', '0', 'R/2', 'R']) axes[1].set_xlabel('Translated Rapidity y') axes[1].set_ylabel('Translated Azimuthal Angle phi') axes[1].set_title('Energy Flow Network Latent Space', fontdict={'fontsize': 10}) plt.show() pfn_example.py An example involving Particle Flow Networks (PFNs), which were introduced in 1810.05165 . The PFN class is used to construct the network architecture. The output of the example is a plot of the ROC curves obtained by the PFN as well as the jet mass and constituent multiplicity observables. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import PFN from energyflow.datasets import qg_jets from energyflow.utils import data_split, remap_pids, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # the commented values correspond to those in 1810.05165 ############################################################################### # data controls, can go up to 2000000 for full dataset train, val, test = 75000, 10000, 15000 # train, val, test = 1000000, 200000, 200000 use_pids = True # network architecture parameters Phi_sizes, F_sizes = (100, 100, 128), (100, 100, 100) # Phi_sizes, F_sizes = (100, 100, 256), (100, 100, 100) # network training parameters num_epoch = 5 batch_size = 500 ################################################################################ # load data X, y = qg_jets.load(train + val + test) # convert labels to categorical Y = to_categorical(y, num_classes=2) print('Loaded quark and gluon jets') # preprocess by centering jets and normalizing pts for x in X: mask = x[:,0] > 0 yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0) x[mask,1:3] -= yphi_avg x[mask,0] /= x[:,0].sum() # handle particle id channel if use_pids: remap_pids(X, pid_i=3) else: X = X[:,:,:3] print('Finished preprocessing') # do train/val/test split (X_train, X_val, X_test, Y_train, Y_val, Y_test) = data_split(X, Y, val=val, test=test) print('Done train/val/test split') print('Model summary:') # build architecture pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes) # train model pfn.fit(X_train, Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=(X_val, Y_val), verbose=1) # get predictions on test data preds = pfn.predict(X_test, batch_size=1000) # get ROC curve if we have sklearn if roc_curve: pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1]) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('PFN AUC:', auc) print() # make ROC curve plot if we have matplotlib if plt: # get multiplicity and mass for comparison masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphims(x).sum(axis=0)) for x in X]) mults = np.asarray([np.count_nonzero(x[:,0]) for x in X]) mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses) mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults) # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # plot the ROC curves plt.plot(pfn_tp, 1-pfn_fp, '-', color='black', label='PFN') plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass') plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity') # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show() cnn_example.py An example involving jet images and convolutional neural networks (CNNs). The CNN class is used to provide a network architecture based on that described in 1612.01551 . Jet images are constructed using the pixelate function and can be either one-channel (grayscale), meaning that only $p_T$ information is used, or two-channel (color), meaning that $p_T$ information and local charged particle counts are used. The images are preprocessed by subtracting the average image in the training set and dividing by the per-pixel standard deviations, using the zero_center and standardize functions, respectively. The output of the example is a plot of the ROC curves of the CNN as well as the jet mass and constituent multiplicity observables. Note that the number of epochs is quite small because it is quite time consuming to train a CNN without a GPU (which will speed up this example immensely). # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import CNN from energyflow.datasets import qg_jets from energyflow.utils import data_split, pixelate, standardize, to_categorical, zero_center # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 100000 val_frac, test_frac = 0.1, 0.15 # image parameters R = 0.4 img_width = 2*R npix = 33 nb_chan = 2 norm = True # required network architecture parameters input_shape = (nb_chan, npix, npix) filter_sizes = [8, 4, 4] num_filters = [8, 8, 8] # very small so can run on non-GPUs in reasonable time # optional network architecture parameters dense_sizes = [50] pool_sizes = 2 # network training parameters num_epoch = 2 batch_size = 100 ################################################################################ # load data X, y = qg_jets.load(num_data=num_data) # convert labels to categorical Y = to_categorical(y, num_classes=2) print('Loaded quark and gluon jets') # make jet images images = np.asarray([pixelate(x, npix=npix, img_width=img_width, nb_chan=nb_chan, charged_counts_only=True, norm=norm) for x in X]) print('Done making jet images') # do train/val/test split (X_train, X_val, X_test, Y_train, Y_val, Y_test) = data_split(images, Y, val=val_frac, test=test_frac) print('Done train/val/test split') # preprocess by zero centering images and standardizing each pixel X_train, X_val, X_test = standardize(*zero_center(X_train, X_val, X_test)) print('Finished preprocessing') print('Model summary:') # build architecture hps = {'input_shape': input_shape, 'filter_sizes': filter_sizes, 'num_filters': num_filters, 'dense_sizes': dense_sizes, 'pool_sizes': pool_sizes} cnn = CNN(hps) # train model cnn.fit(X_train, Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=(X_val, Y_val), verbose=1) # get predictions on test data preds = cnn.predict(X_test, batch_size=1000) # get ROC curve if we have sklearn if roc_curve: cnn_fp, cnn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1]) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('CNN AUC:', auc) print() # make ROC curve plot if we have matplotlib if plt: # get multiplicity and mass for comparison masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphims(x).sum(axis=0)) for x in X]) mults = np.asarray([np.count_nonzero(x[:,0]) for x in X]) mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses) mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults) # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # plot the ROC curves plt.plot(cnn_tp, 1-cnn_fp, '-', color='black', label='CNN') plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass') plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity') # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show() dnn_example.py An example involving deep, fully-connected neural networks (DNNs). The DNN class is used to construct the network architecture. The inputs are taken to be the $N$-subjettiness observables as specified as part of the phase space basis from 1704.08249 , cut off at some total number of observables. The output of the example is a plot showing the ROC curves obtained from training the DNN on different numbers of $N$-subjettiness observables. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import DNN from energyflow.datasets import qg_nsubs from energyflow.utils import data_split, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 100000 val_frac, test_frac = 0.1, 0.15 # network architecture parameters dense_sizes = (100, 100) # network training parameters num_epoch = 10 batch_size = 100 # sweep parameters num_nsubs = [1, 2, 4, 8, 16, 32] colors = ['tab:red', 'tab:orange', 'tab:olive', 'tab:green', 'tab:blue', 'tab:purple'] ################################################################################ # load data X, y = qg_nsubs.load(num_data=num_data) # convert labels to categorical Y = to_categorical(y, num_classes=2) print('Loaded quark and gluon jets') print('Model summary:') # train models with different numbers of nsubs as input rocs = [] for i,num_nsub in enumerate(num_nsubs): # build architecture dnn = DNN(input_dim=num_nsub, dense_sizes=dense_sizes, summary=(i==0)) # do train/val/test split (X_train, X_val, X_test, Y_train, Y_val, Y_test) = data_split(X[:,:num_nsub], Y, val=val_frac, test=test_frac) print('Done train/val/test split') # train model dnn.fit(X_train, Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=(X_val, Y_val), verbose=1) # get predictions on test data preds = dnn.predict(X_test, batch_size=1000) # get ROC curve if we have sklearn if roc_curve: rocs.append(roc_curve(Y_test[:,1], preds[:,1])) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('{} nsubs DNN AUC:'.format(num_nsub), auc) print() # make ROC curve plot if we have matplotlib if plt: # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # iterate over the ROC curves and plot them for i in range(len(rocs)): plt.plot(rocs[i][1], 1-rocs[i][0], '-', color=colors[i], label='DNN: {} N-subs'.format(num_nsubs[i])) # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show()","title":"Examples"},{"location":"examples/#efp_examplepy","text":"An example involving Energy Flow Polynomials (EFPs) and a linear classifier (Fisher's Linear Discriminant by default). First, the EFPSet class is used to compute the EFPs up to the specified dmax , the default being dmax=5 . Then linear classifiers are trained for different numbers of EFPs as input, determined by taking all EFPs up to degree d with d from 1 to dmax . The output of the example is a plot of the ROC curves for the classifiers with different numbers of EFP inputs. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import LinearClassifier from energyflow.datasets import qg_jets from energyflow.utils import data_split, standardize, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 20000 test_frac = 0.2 # efp parameters dmax = 5 measure = 'hadr' beta = 0.5 # plotting colors = ['tab:red', 'tab:orange', 'tab:olive', 'tab:green', 'tab:blue'] ################################################################################ # load data X, y = qg_jets.load(num_data) print('Loaded quark and gluon jets') # calculate EFPs print('Calculating d <= {} EFPs for {} jets... '.format(dmax, num_data), end='') efpset = ef.EFPSet(('d<=', dmax), measure='hadr', beta=beta) masked_X = [x[x[:,0] > 0] for x in X] X = efpset.batch_compute(masked_X) print('Done') # train models with different numbers of EFPs as input rocs = [] for d in range(1, dmax+1): # build architecture model = LinearClassifier(linclass_type='lda') # select EFPs with degree <= d X_d = X[:,efpset.sel(('d<=', d))] # do train/val/test split (X_train, X_test, y_train, y_test) = data_split(X_d, y, val=0, test=test_frac) print('Done train/val/test split') # train model model.fit(X_train, y_train) # get predictions on test data preds = model.predict(X_test) # get ROC curve if we have sklearn if roc_curve: rocs.append(roc_curve(y_test, preds[:,1])) # get area under the ROC curve auc = roc_auc_score(y_test, preds[:,1]) print() print('EFPs d <= {} AUC:'.format(d), auc) print() # make ROC curve plot if we have matplotlib if plt: # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # iterate over the ROC curves and plot them for i,d in enumerate(range(1, dmax+1)): plt.plot(rocs[i][1], 1-rocs[i][0], '-', color=colors[i], label='LDA: d <= {} EFPs'.format(d)) # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show()","title":"efp_example.py"},{"location":"examples/#efn_examplepy","text":"An example involving Energy Flow Networks (EFNs), which were introduced in 1810.05165 . The EFN class is used to construct the network architecture. The output of the example is a plot of the ROC curves obtained by the EFN as well as the jet mass and constituent multiplicity observables. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import EFN from energyflow.datasets import qg_jets from energyflow.utils import data_split, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################## # the commented values correspond to those in 1810.05165 ############################################################################### # data controls, can go up to 2000000 total for full dataset train, val, test = 75000, 10000, 15000 # train, val, test = 1000000, 200000, 200000 # network architecture parameters Phi_sizes, F_sizes = (100, 100, 128), (100, 100, 100) # Phi_sizes, F_sizes = (100, 100, 256), (100, 100, 100) # network training parameters num_epoch = 5 batch_size = 500 ############################################################################### # load data X, y = qg_jets.load(train + val + test) # ignore pid information X = X[:,:,:3] # convert labels to categorical Y = to_categorical(y, num_classes=2) print('Loaded quark and gluon jets') # preprocess by centering jets and normalizing pts for x in X: mask = x[:,0] > 0 yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0) x[mask,1:3] -= yphi_avg x[mask,0] /= x[:,0].sum() print('Finished preprocessing') # do train/val/test split (z_train, z_val, z_test, p_train, p_val, p_test, Y_train, Y_val, Y_test) = data_split(X[:,:,0], X[:,:,1:], Y, val=val, test=test) print('Done train/val/test split') print('Model summary:') # build architecture efn = EFN(input_dim=2, Phi_sizes=Phi_sizes, F_sizes=F_sizes) # train model efn.fit([z_train, p_train], Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=([z_val, p_val], Y_val), verbose=1) # get predictions on test data preds = efn.predict([z_test, p_test], batch_size=1000) # get ROC curve if we have sklearn if roc_curve: efn_fp, efn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1]) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('EFN AUC:', auc) print() # make ROC curve and filter plot if we have matplotlib if plt: # some nicer plot settings plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True fig, axes = plt.subplots(1, 2, figsize=(8,4)) ######################### ROC Curve Plot ######################### # get multiplicity and mass for comparison masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphims(x).sum(axis=0)) for x in X]) mults = np.asarray([np.count_nonzero(x[:,0]) for x in X]) mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses) mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults) # plot the ROC curves axes[0].plot(efn_tp, 1-efn_fp, '-', color='black', label='EFN') axes[0].plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass') axes[0].plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity') # axes labels axes[0].set_xlabel('Quark Jet Efficiency') axes[0].set_ylabel('Gluon Jet Rejection') # axes limits axes[0].set_xlim(0, 1) axes[0].set_ylim(0, 1) # make legend and show plot axes[0].legend(loc='lower left', frameon=False) ######################### Filter Plot ######################### # plot settings R, n = 0.4, 100 colors = ['Reds', 'Oranges', 'Greens', 'Blues', 'Purples', 'Greys'] grads = np.linspace(0.45, 0.55, 4) # evaluate filters X, Y, Z = efn.eval_filters(R, n=n) # plot filters for i,z in enumerate(Z): axes[1].contourf(X, Y, z/np.max(z), grads, cmap=colors[i%len(colors)]) axes[1].set_xticks(np.linspace(-R, R, 5)) axes[1].set_yticks(np.linspace(-R, R, 5)) axes[1].set_xticklabels(['-R', '-R/2', '0', 'R/2', 'R']) axes[1].set_yticklabels(['-R', '-R/2', '0', 'R/2', 'R']) axes[1].set_xlabel('Translated Rapidity y') axes[1].set_ylabel('Translated Azimuthal Angle phi') axes[1].set_title('Energy Flow Network Latent Space', fontdict={'fontsize': 10}) plt.show()","title":"efn_example.py"},{"location":"examples/#pfn_examplepy","text":"An example involving Particle Flow Networks (PFNs), which were introduced in 1810.05165 . The PFN class is used to construct the network architecture. The output of the example is a plot of the ROC curves obtained by the PFN as well as the jet mass and constituent multiplicity observables. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import PFN from energyflow.datasets import qg_jets from energyflow.utils import data_split, remap_pids, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # the commented values correspond to those in 1810.05165 ############################################################################### # data controls, can go up to 2000000 for full dataset train, val, test = 75000, 10000, 15000 # train, val, test = 1000000, 200000, 200000 use_pids = True # network architecture parameters Phi_sizes, F_sizes = (100, 100, 128), (100, 100, 100) # Phi_sizes, F_sizes = (100, 100, 256), (100, 100, 100) # network training parameters num_epoch = 5 batch_size = 500 ################################################################################ # load data X, y = qg_jets.load(train + val + test) # convert labels to categorical Y = to_categorical(y, num_classes=2) print('Loaded quark and gluon jets') # preprocess by centering jets and normalizing pts for x in X: mask = x[:,0] > 0 yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0) x[mask,1:3] -= yphi_avg x[mask,0] /= x[:,0].sum() # handle particle id channel if use_pids: remap_pids(X, pid_i=3) else: X = X[:,:,:3] print('Finished preprocessing') # do train/val/test split (X_train, X_val, X_test, Y_train, Y_val, Y_test) = data_split(X, Y, val=val, test=test) print('Done train/val/test split') print('Model summary:') # build architecture pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes) # train model pfn.fit(X_train, Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=(X_val, Y_val), verbose=1) # get predictions on test data preds = pfn.predict(X_test, batch_size=1000) # get ROC curve if we have sklearn if roc_curve: pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1]) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('PFN AUC:', auc) print() # make ROC curve plot if we have matplotlib if plt: # get multiplicity and mass for comparison masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphims(x).sum(axis=0)) for x in X]) mults = np.asarray([np.count_nonzero(x[:,0]) for x in X]) mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses) mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults) # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # plot the ROC curves plt.plot(pfn_tp, 1-pfn_fp, '-', color='black', label='PFN') plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass') plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity') # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show()","title":"pfn_example.py"},{"location":"examples/#cnn_examplepy","text":"An example involving jet images and convolutional neural networks (CNNs). The CNN class is used to provide a network architecture based on that described in 1612.01551 . Jet images are constructed using the pixelate function and can be either one-channel (grayscale), meaning that only $p_T$ information is used, or two-channel (color), meaning that $p_T$ information and local charged particle counts are used. The images are preprocessed by subtracting the average image in the training set and dividing by the per-pixel standard deviations, using the zero_center and standardize functions, respectively. The output of the example is a plot of the ROC curves of the CNN as well as the jet mass and constituent multiplicity observables. Note that the number of epochs is quite small because it is quite time consuming to train a CNN without a GPU (which will speed up this example immensely). # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import CNN from energyflow.datasets import qg_jets from energyflow.utils import data_split, pixelate, standardize, to_categorical, zero_center # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 100000 val_frac, test_frac = 0.1, 0.15 # image parameters R = 0.4 img_width = 2*R npix = 33 nb_chan = 2 norm = True # required network architecture parameters input_shape = (nb_chan, npix, npix) filter_sizes = [8, 4, 4] num_filters = [8, 8, 8] # very small so can run on non-GPUs in reasonable time # optional network architecture parameters dense_sizes = [50] pool_sizes = 2 # network training parameters num_epoch = 2 batch_size = 100 ################################################################################ # load data X, y = qg_jets.load(num_data=num_data) # convert labels to categorical Y = to_categorical(y, num_classes=2) print('Loaded quark and gluon jets') # make jet images images = np.asarray([pixelate(x, npix=npix, img_width=img_width, nb_chan=nb_chan, charged_counts_only=True, norm=norm) for x in X]) print('Done making jet images') # do train/val/test split (X_train, X_val, X_test, Y_train, Y_val, Y_test) = data_split(images, Y, val=val_frac, test=test_frac) print('Done train/val/test split') # preprocess by zero centering images and standardizing each pixel X_train, X_val, X_test = standardize(*zero_center(X_train, X_val, X_test)) print('Finished preprocessing') print('Model summary:') # build architecture hps = {'input_shape': input_shape, 'filter_sizes': filter_sizes, 'num_filters': num_filters, 'dense_sizes': dense_sizes, 'pool_sizes': pool_sizes} cnn = CNN(hps) # train model cnn.fit(X_train, Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=(X_val, Y_val), verbose=1) # get predictions on test data preds = cnn.predict(X_test, batch_size=1000) # get ROC curve if we have sklearn if roc_curve: cnn_fp, cnn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1]) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('CNN AUC:', auc) print() # make ROC curve plot if we have matplotlib if plt: # get multiplicity and mass for comparison masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphims(x).sum(axis=0)) for x in X]) mults = np.asarray([np.count_nonzero(x[:,0]) for x in X]) mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses) mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults) # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # plot the ROC curves plt.plot(cnn_tp, 1-cnn_fp, '-', color='black', label='CNN') plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass') plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity') # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show()","title":"cnn_example.py"},{"location":"examples/#dnn_examplepy","text":"An example involving deep, fully-connected neural networks (DNNs). The DNN class is used to construct the network architecture. The inputs are taken to be the $N$-subjettiness observables as specified as part of the phase space basis from 1704.08249 , cut off at some total number of observables. The output of the example is a plot showing the ROC curves obtained from training the DNN on different numbers of $N$-subjettiness observables. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import DNN from energyflow.datasets import qg_nsubs from energyflow.utils import data_split, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 100000 val_frac, test_frac = 0.1, 0.15 # network architecture parameters dense_sizes = (100, 100) # network training parameters num_epoch = 10 batch_size = 100 # sweep parameters num_nsubs = [1, 2, 4, 8, 16, 32] colors = ['tab:red', 'tab:orange', 'tab:olive', 'tab:green', 'tab:blue', 'tab:purple'] ################################################################################ # load data X, y = qg_nsubs.load(num_data=num_data) # convert labels to categorical Y = to_categorical(y, num_classes=2) print('Loaded quark and gluon jets') print('Model summary:') # train models with different numbers of nsubs as input rocs = [] for i,num_nsub in enumerate(num_nsubs): # build architecture dnn = DNN(input_dim=num_nsub, dense_sizes=dense_sizes, summary=(i==0)) # do train/val/test split (X_train, X_val, X_test, Y_train, Y_val, Y_test) = data_split(X[:,:num_nsub], Y, val=val_frac, test=test_frac) print('Done train/val/test split') # train model dnn.fit(X_train, Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=(X_val, Y_val), verbose=1) # get predictions on test data preds = dnn.predict(X_test, batch_size=1000) # get ROC curve if we have sklearn if roc_curve: rocs.append(roc_curve(Y_test[:,1], preds[:,1])) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('{} nsubs DNN AUC:'.format(num_nsub), auc) print() # make ROC curve plot if we have matplotlib if plt: # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # iterate over the ROC curves and plot them for i in range(len(rocs)): plt.plot(rocs[i][1], 1-rocs[i][0], '-', color=colors[i], label='DNN: {} N-subs'.format(num_nsubs[i])) # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show()","title":"dnn_example.py"},{"location":"faqs/","text":"Frequently Asked EnergyFlow Questions How do I cite the EnergyFlow package? Why Python instead of C++? Can I contribute to the code? How do I report an issue or a bug? Where can I get graph image files? How do I cite the EnergyFlow package? Please cite the relevant papers if they or this package help your research. Here are the BibTeX entries to use: @article{Komiske:2017aww, author = \"Komiske, Patrick T. and Metodiev, Eric M. and Thaler, Jesse\", title = \"{Energy Flow Polynomials: A complete linear basis for jet substructure}\", journal = \"JHEP\", volume = \"04\", year = \"2018\", pages = \"013\", doi = \"10.1007/JHEP04(2018)013\", eprint = \"1712.07124\", archivePrefix = \"arXiv\", primaryClass = \"hep-ph\", reportNumber = \"MIT-CTP-4965\" } @article{Komiske:2018cqr, author = \"Komiske, Patrick T. and Metodiev, Eric M. and Thaler, Jesse\", title = \"{Energy Flow Networks: Deep Sets for Particle Jets}\", journal = \"JHEP\", volume = \"01\", year = \"2019\", pages = \"121\", doi = \"10.1007/JHEP01(2019)121\", eprint = \"1810.05165\", archivePrefix = \"arXiv\", primaryClass = \"hep-ph\", reportNumber = \"MIT-CTP 5064\" } @article{Komiske:2019fks, author = \"Komiske, Patrick T. and Metodiev, Eric M. and Thaler, Jesse\", title = \"{The Metric Space of Collider Events}\", year = \"2019\", eprint = \"1902.02346\", archivePrefix = \"arXiv\", primaryClass = \"hep-ph\", reportNumber = \"MIT-CTP 5102\" } Why Python instead of C++? Computing the EFPs requires a function such as NumPy's einsum that can efficiently evaluate arbitrary tensor contractions. To write such a function from scratch in C++ is difficult, and there is no obvious library in C++ to use (though if one were to attempt this the tensor algebra compiler seems like a promising tool). NumPy is a highly-optimized Python library written in C that provides all of the tools required to efficiently compute the EFPs. Libraries like NumPy take advantage of optimizations that the physicist-programmer typically does not, such as architecture-optimized libraries like BLAS or LAPACK and low-level features such as SSE/AVX instructions. Beyond just computing EFPs, EnergyFlow makes use of other libraries written in python including Keras and scikit-learn for the architecture implementations, POT and SciPy for EMD computations, and matplotlib for the examples. Can I contribute to the code? All of our code is open source and hosted on GitHub . We welcome additional contributors, and if you are interested in getting involved please contact us directly. Contact information is included in the relevant Energy Flow papers and our GitHub repository. How do I report an issue? Please let us know of any issues you encounter as soon as possible by creating a GitHub Issue . Where can I get graph image files? Image files for all connected multigraphs with up to 7 edges in the EFP style are available as PDF files here . You are free to use them with the proper attribution.","title":"FAQs"},{"location":"faqs/#frequently-asked-energyflow-questions","text":"How do I cite the EnergyFlow package? Why Python instead of C++? Can I contribute to the code? How do I report an issue or a bug? Where can I get graph image files?","title":"Frequently Asked EnergyFlow Questions"},{"location":"faqs/#how-do-i-cite-the-energyflow-package","text":"Please cite the relevant papers if they or this package help your research. Here are the BibTeX entries to use: @article{Komiske:2017aww, author = \"Komiske, Patrick T. and Metodiev, Eric M. and Thaler, Jesse\", title = \"{Energy Flow Polynomials: A complete linear basis for jet substructure}\", journal = \"JHEP\", volume = \"04\", year = \"2018\", pages = \"013\", doi = \"10.1007/JHEP04(2018)013\", eprint = \"1712.07124\", archivePrefix = \"arXiv\", primaryClass = \"hep-ph\", reportNumber = \"MIT-CTP-4965\" } @article{Komiske:2018cqr, author = \"Komiske, Patrick T. and Metodiev, Eric M. and Thaler, Jesse\", title = \"{Energy Flow Networks: Deep Sets for Particle Jets}\", journal = \"JHEP\", volume = \"01\", year = \"2019\", pages = \"121\", doi = \"10.1007/JHEP01(2019)121\", eprint = \"1810.05165\", archivePrefix = \"arXiv\", primaryClass = \"hep-ph\", reportNumber = \"MIT-CTP 5064\" } @article{Komiske:2019fks, author = \"Komiske, Patrick T. and Metodiev, Eric M. and Thaler, Jesse\", title = \"{The Metric Space of Collider Events}\", year = \"2019\", eprint = \"1902.02346\", archivePrefix = \"arXiv\", primaryClass = \"hep-ph\", reportNumber = \"MIT-CTP 5102\" }","title":"How do I cite the EnergyFlow package?"},{"location":"faqs/#why-python-instead-of-c","text":"Computing the EFPs requires a function such as NumPy's einsum that can efficiently evaluate arbitrary tensor contractions. To write such a function from scratch in C++ is difficult, and there is no obvious library in C++ to use (though if one were to attempt this the tensor algebra compiler seems like a promising tool). NumPy is a highly-optimized Python library written in C that provides all of the tools required to efficiently compute the EFPs. Libraries like NumPy take advantage of optimizations that the physicist-programmer typically does not, such as architecture-optimized libraries like BLAS or LAPACK and low-level features such as SSE/AVX instructions. Beyond just computing EFPs, EnergyFlow makes use of other libraries written in python including Keras and scikit-learn for the architecture implementations, POT and SciPy for EMD computations, and matplotlib for the examples.","title":"Why Python instead of C++?"},{"location":"faqs/#can-i-contribute-to-the-code","text":"All of our code is open source and hosted on GitHub . We welcome additional contributors, and if you are interested in getting involved please contact us directly. Contact information is included in the relevant Energy Flow papers and our GitHub repository.","title":"Can I contribute to the code?"},{"location":"faqs/#how-do-i-report-an-issue","text":"Please let us know of any issues you encounter as soon as possible by creating a GitHub Issue .","title":"How do I report an issue?"},{"location":"faqs/#where-can-i-get-graph-image-files","text":"Image files for all connected multigraphs with up to 7 edges in the EFP style are available as PDF files here . You are free to use them with the proper attribution.","title":"Where can I get graph image files?"},{"location":"installation/","text":"The EnergyFlow package is written in pure Python and the core depends only on NumPy, the fundamental package for scientific computing with Python, and six, which is a lightweight module to patch some inconvenient differences between Python 2 and Python 3. The extra features require additional packages as specified below: Architectures: Keras , scikit-learn . EMD: Python Optimal Transport (POT) . Multigraph Generation: iGraph The EnergyFlow package is designed to work with Python 2.7, 3.5, 3.6, and 3.7. These can be installed from here . A recent version of Python 3 is highly recommended, ideally 3.6 or higher. Install via pip To install from PyPI using pip , make sure you have one of the supported versions of Python installed and that pip is available in the system path. Simply execute pip install energyflow and EnergyFlow will be installed in your default location for Python packages. NumPy As of version 0.8.2 , EnergyFlow has used a modified version of numpy.einsum to do the heavy lifting for the computation of EFPs. NumPy 1.14.0 changed einsum to use tensordot when possible compared to 1.13.3 , which only used c_einsum . It was found that the multi-process approach used by batch_compute is typically much faster when using the inherently single-threaded c_einsum versus tensordot , which can call BLAS. Hence the custom version of einsum shipped with EnergyFlow disables all calls to tensordot and uses only c_einsum .","title":"Installation"},{"location":"installation/#install-via-pip","text":"To install from PyPI using pip , make sure you have one of the supported versions of Python installed and that pip is available in the system path. Simply execute pip install energyflow and EnergyFlow will be installed in your default location for Python packages.","title":"Install via pip"},{"location":"installation/#numpy","text":"As of version 0.8.2 , EnergyFlow has used a modified version of numpy.einsum to do the heavy lifting for the computation of EFPs. NumPy 1.14.0 changed einsum to use tensordot when possible compared to 1.13.3 , which only used c_einsum . It was found that the multi-process approach used by batch_compute is typically much faster when using the inherently single-threaded c_einsum versus tensordot , which can call BLAS. Hence the custom version of einsum shipped with EnergyFlow disables all calls to tensordot and uses only c_einsum .","title":"NumPy"},{"location":"releases/","text":"Notes regarding the released versions of EnergyFlow will be published here. 0.12.x 0.12.0 Fixed potential issue involving the Keras Masking layer not functioning as documented. This is not expected to affect any EFN models that were padded with zeros, nor any PFN models for which the padding was consistent across training and testing sets. Thanks to Anders Andreassen for pointing this out! Added arbitrary attribute lookup in the underlying model for all EnergyFlow architectures. Deprecated old EFN/PFN parameter names. Built-in support for ModelCheckpoint and EarlyStopping callbacks for neural network models. Made naming of neural network layers optional, allowing pieces to be reused more easily. Support for periodic phi values in EMD module. Added support for passing arbitrary compilation options to Keras models. Added EMD Demo notebook 0.11.x 0.11.2 Added advanced activations support for neural network architectures. Thanks to Kevin Bauer for this suggestion! 0.11.1 Fixed issue when using Python 2 caused by not importing division in dataset loading code. Thanks to Matt LeBlanc for pointing this out! Added n_iter_max option to EMD functions. 0.11.0 Added emd module to EnergyFlow. This new module is not imported by default and relies on the Python Optimal Transport library and SciPy . 0.10.x 0.10.5 Minor improvement and fixes. Thanks to Preksha Naik for pointing out a typo! 0.10.4 Updates to the documentation and enhanced examples provided. 0.10.3 Finalized initial documentation pages. Minor improvement and fixes. 0.10.2 Minor improvement and fixes. 0.10.1 Minor improvement and fixes. 0.10.0 Added archs module containing EFN, PFN, DNN, CNN, and Linear models. <0.9.x Rapid development of EFP code.","title":"Release Notes"},{"location":"releases/#012x","text":"0.12.0 Fixed potential issue involving the Keras Masking layer not functioning as documented. This is not expected to affect any EFN models that were padded with zeros, nor any PFN models for which the padding was consistent across training and testing sets. Thanks to Anders Andreassen for pointing this out! Added arbitrary attribute lookup in the underlying model for all EnergyFlow architectures. Deprecated old EFN/PFN parameter names. Built-in support for ModelCheckpoint and EarlyStopping callbacks for neural network models. Made naming of neural network layers optional, allowing pieces to be reused more easily. Support for periodic phi values in EMD module. Added support for passing arbitrary compilation options to Keras models. Added EMD Demo notebook","title":"0.12.x"},{"location":"releases/#011x","text":"0.11.2 Added advanced activations support for neural network architectures. Thanks to Kevin Bauer for this suggestion! 0.11.1 Fixed issue when using Python 2 caused by not importing division in dataset loading code. Thanks to Matt LeBlanc for pointing this out! Added n_iter_max option to EMD functions. 0.11.0 Added emd module to EnergyFlow. This new module is not imported by default and relies on the Python Optimal Transport library and SciPy .","title":"0.11.x"},{"location":"releases/#010x","text":"0.10.5 Minor improvement and fixes. Thanks to Preksha Naik for pointing out a typo! 0.10.4 Updates to the documentation and enhanced examples provided. 0.10.3 Finalized initial documentation pages. Minor improvement and fixes. 0.10.2 Minor improvement and fixes. 0.10.1 Minor improvement and fixes. 0.10.0 Added archs module containing EFN, PFN, DNN, CNN, and Linear models.","title":"0.10.x"},{"location":"releases/#09x","text":"Rapid development of EFP code.","title":"&lt;0.9.x"},{"location":"docs/archs/","text":"Energy Flow Networks (EFNs) and Particle Flow Networks (PFNs) are model architectures designed for learning from collider events as unordered, variable-length sets of particles. Both EFNs and PFNs are parameterized by a learnable per-particle function $\\Phi$ and latent space function $F$. An EFN takes the following form: \\text{EFN}=F\\left(\\sum_{i=1}^M z_i \\Phi(\\hat p_i)\\right) where $z_i$ is a measure of the energy of particle $i$, such as $z_i=p_{T,i}$, and $\\hat p_i$ is a measure of the angular information of particle $i$, such as $\\hat p_i = (y_i,\\phi_i)$. Any infrared- and collinear-safe observable can be parameterized in this form. A PFN takes the following form: \\text{PFN}=F\\left(\\sum_{i=1}^M \\Phi(p_i)\\right) where $p_i$ is the information of particle $i$, such as its four-momentum, charge, or flavor. Any observable can be parameterized in this form. See the Deep Sets framework for additional discussion. Since these architectures are not used by the core EnergyFlow code, and require the external Keras and scikit-learn libraries, they are not imported by default but must be explicitly imported, e.g. from energyflow.archs import * . EnergyFlow also contains several additional model architectures for ease of using common models that frequently appear in the intersection of particle physics and machine learning. EFN Energy Flow Network (EFN) architecture. energyflow.archs.EFN(*args, **kwargs) See ArchBase for how to pass in hyperparameters as well as hyperparameters common to all EnergyFlow neural network models. Required EFN Hyperparameters input_dim : int The number of features for each particle. Phi_sizes (formerly ppm_sizes ) : { tuple , list } of int The sizes of the dense layers in the per-particle frontend module $\\Phi$. The last element will be the number of latent observables that the model defines. F_sizes (formerly dense_sizes ) : { tuple , list } of int The sizes of the dense layers in the backend module $F$. Default EFN Hyperparameters Phi_acts = 'relu' (formerly ppm_acts ) : { tuple , list } of str or Keras activation Activation functions(s) for the dense layers in the per-particle frontend module $\\Phi$. A single string or activation layer will apply the same activation to all layers. Keras advanced activation layers are also accepted, either as strings (which use the default arguments) or as Keras Layer instances. If passing a single Layer instance, be aware that this layer will be used for all activations and may introduce weight sharing (such as with PReLU ); it is recommended in this case to pass as many activations as there are layers in the model. See the Keras activations docs for more detail. F_acts = 'relu' (formerly dense_acts ) : { tuple , list } of str or Keras activation Activation functions(s) for the dense layers in the backend module $F$. A single string or activation layer will apply the same activation to all layers. Phi_k_inits = 'he_uniform' (formerly ppm_k_inits ) : { tuple , list } of str or Keras initializer Kernel initializers for the dense layers in the per-particle frontend module $\\Phi$. A single string will apply the same initializer to all layers. See the Keras initializer docs for more detail. F_k_inits = 'he_uniform' (formerly dense_k_inits ) : { tuple , list } of str or Keras initializer Kernel initializers for the dense layers in the backend module $F$. A single string will apply the same initializer to all layers. latent_dropout = 0 : float Dropout rates for the summation layer that defines the value of the latent observables on the inputs. See the Keras Dropout layer for more detail. F_dropouts = 0 (formerly dense_dropouts ) : { tuple , list } of float Dropout rates for the dense layers in the backend module $F$. A single float will apply the same dropout rate to all dense layers. mask_val = 0 : float The value for which particles with all features set equal to this value will be ignored. See the Keras Masking layer for more detail. eval_filters eval_filters(patch, n=100, prune=True) Evaluates the latent space filters of this model on a patch of the two-dimensional geometric input space. Arguments patch : { tuple , list } of float Specifies the patch of the geometric input space to be evaluated. A list of length 4 is interpretted as [xmin, ymin, xmax, ymax] . Passing a single float R is equivalent to [-R,-R,R,R] . n : { tuple , list } of int The number of grid points on which to evaluate the filters. A list of length 2 is interpretted as [nx, ny] where nx is the number of points along the x (or first) dimension and ny is the number of points along the y (or second) dimension. prune : bool Whether to remove filters that are all zero (which happens sometimes due to dying ReLUs). Returns ( numpy.ndarray , numpy.ndarray , numpy.ndarray ) Returns three arrays, (X, Y, Z) , where X and Y have shape (nx, ny) and are arrays of the values of the geometric inputs in the specified patch. Z has shape (num_filters, nx, ny) and is the value of the different filters at each point. inputs inputs List of input tensors to the model. EFNs have two input tensors: inputs[0] corresponds to the zs input and inputs[1] corresponds to the phats input. weights weights Weight tensor for the model. This is the zs input where entries equal to mask_val have been set to zero. Phi Phi List of tensors corresponding to the layers in the $\\Phi$ network. latent latent List of tensors corresponding to the summation layer in the network, including any dropout layer if present. F F List of tensors corresponding to the layers in the $F$ network. output output Output tensor for the model. PFN Particle Flow Network (PFN) architecture. Accepts the same hyperparameters as the EFN . energyflow.archs.PFN(*args, **kwargs) inputs inputs List of input tensors to the model. PFNs have one input tensor corresponding to the ps input. weights weights Weight tensor for the model. A weight of 0 is assigned to any particle which has all features equal to mask_val , and 1 is assigned otherwise. Phi Phi List of tensors corresponding to the layers in the $\\Phi$ network. latent latent List of tensors corresponding to the summation layer in the network, including any dropout layer if present. F F List of tensors corresponding to the layers in the $F$ network. output output Output tensor for the model. CNN Convolutional Neural Network architecture. energyflow.archs.CNN(*args, **kwargs) See ArchBase for how to pass in hyperparameters as well as hyperparameters common to all EnergyFlow neural network models. Required CNN Hyperparameters input_shape : { tuple , list } of int The shape of a single jet image. Assuming that data_format is set to channels_first , this is (nb_chan,npix,npix) . filter_sizes : { tuple , list } of int The size of the filters, which are taken to be square, in each convolutional layer of the network. The length of the list will be the number of convolutional layers in the network. num_filters : { tuple , list } of int The number of filters in each convolutional layer. The length of num_filters must match that of filter_sizes . Default CNN Hyperparameters dense_sizes = None : { tuple , list } of int The sizes of the dense layer backend. A value of None is equivalent to an empty list. pool_sizes = None : { tuple , list } of int Size of maxpooling filter, taken to be a square. A value of None will not use maxpooling. conv_acts = 'relu' : { tuple , list } of str or Keras activation Activation function(s) for the conv layers. A single string or activation layer will apply the same activation to all conv layers. Keras advanced activation layers are also accepted, either as strings (which use the default arguments) or as Keras Layer instances. If passing a single Layer instance, be aware that this layer will be used for all activations and may introduce weight sharing (such as with PReLU ); it is recommended in this case to pass as many activations as there are layers in the model.See the Keras activations docs for more detail. dense_acts = 'relu' : { tuple , list } of str or Keras activation Activation functions(s) for the dense layers. A single string or activation layer will apply the same activation to all dense layers. conv_k_inits = 'he_uniform' : { tuple , list } of str or Keras initializer Kernel initializers for the convolutional layers. A single string will apply the same initializer to all layers. See the Keras initializer docs for more detail. dense_k_inits = 'he_uniform' : { tuple , list } of str or Keras initializer Kernel initializers for the dense layers. A single string will apply the same initializer to all layers. conv_dropouts = 0 : { tuple , list } of float Dropout rates for the convolutional layers. A single float will apply the same dropout rate to all conv layers. See the Keras Dropout layer for more detail. num_spatial2d_dropout = 0 : int The number of convolutional layers, starting from the beginning of the model, for which to apply SpatialDropout2D instead of Dropout. dense_dropouts = 0 : { tuple , list } of float Dropout rates for the dense layers. A single float will apply the same dropout rate to all dense layers. paddings = 'valid' : { tuple , list } of str Controls how the filters are convoled with the inputs. See the Keras Conv2D layer for more detail. data_format = 'channels_first' : { 'channels_first' , 'channels_last' } Sets which axis is expected to contain the different channels. DNN Dense Neural Network architecture. energyflow.archs.DNN(*args, **kwargs) See ArchBase for how to pass in hyperparameters as well as hyperparameters common to all EnergyFlow neural network models. Required DNN Hyperparameters input_dim : int The number of inputs to the model. dense_sizes : { tuple , list } of int The number of nodes in the dense layers of the model. Default DNN Hyperparameters acts = 'relu' : { tuple , list } of str or Keras activation Activation functions(s) for the dense layers. A single string or activation layer will apply the same activation to all dense layers. Keras advanced activation layers are also accepted, either as strings (which use the default arguments) or as Keras Layer instances. If passing a single Layer instance, be aware that this layer will be used for all activations and may introduce weight sharing (such as with PReLU ); it is recommended in this case to pass as many activations as there are layers in the model.See the Keras activations docs for more detail. k_inits = 'he_uniform' : { tuple , list } of str or Keras initializer Kernel initializers for the dense layers. A single string will apply the same initializer to all layers. See the Keras initializer docs for more detail. dropouts = 0 : { tuple , list } of float Dropout rates for the dense layers. A single float will apply the same dropout rate to all layers. See the Keras Dropout layer for more detail. l2_regs = 0 : { tuple , list } of float $L_2$-regulatization strength for both the weights and biases of the dense layers. A single float will apply the same $L_2$-regulatization to all layers. LinearClassifier Linear classifier that can be either Fisher's linear discriminant or logistic regression. Relies on the scikit-learn implementations of these classifiers. energyflow.archs.LinearClassifier(*args, **kwargs) See ArchBase for how to pass in hyperparameters. Default Hyperparameters linclass_type = 'lda' : { 'lda' , 'lr' } Controls which type of linear classifier is used. 'lda' corresponds to LinearDisciminantAnalysis and 'lr' to Logistic Regression . If using 'lr' all arguments are passed on directly to the scikit-learn class. Linear Discriminant Analysis Hyperparameters solver = 'svd' : { 'svd' , 'lsqr' , 'eigen' } Which LDA solver to use. tol = 1e-12 : float Threshold used for rank estimation. Notably not a convergence parameter. Logistic Regression Hyperparameters LR_hps = {} : dict Dictionary of keyword arguments to pass on to the underlying LogisticRegression model. ArchBase Base class for all architectures contained in EnergyFlow. The mechanism of specifying hyperparameters for all architectures is described here. Methods common to all architectures are documented here. Note that this class cannot be instantiated directly as it is an abstract base class. energyflow.archs.archbase.ArchBase(*args, **kwargs) Accepts arbitrary arguments. Positional arguments (if present) are dictionaries of hyperparameters, keyword arguments (if present) are hyperparameters directly. Keyword hyperparameters take precedence over positional hyperparameter dictionaries. Arguments *args : arbitrary positional arguments Each argument is a dictionary containing hyperparameter (name, value) pairs. *kwargs : arbitrary keyword arguments Hyperparameters as keyword arguments. Takes precedence over the positional arguments. Default NN Hyperparameters Common hyperparameters that apply to all architectures except for LinearClassifier . Compilation Options loss = 'categorical_crossentropy' : str The loss function to use for the model. See the Keras loss function docs for available loss functions. optimizer = 'adam' : Keras optimizer or str A Keras optimizer instance or a string referring to one (in which case the default arguments are used). metrics = ['accuracy'] : list of str The Keras metrics to apply to the model. compile_opts = {} : dict Dictionary of keyword arguments to be passed on to the compile method of the model. loss , optimizer , and metrics (see above) are included in this dictionary. All other values are the Keras defaults. Output Options output_dim = 2 : int The output dimension of the model. output_act = 'softmax' : str or Keras activation Activation function to apply to the output. Callback Options filepath = None : str The file path for where to save the model. If None then the model will not be saved. save_while_training = True : bool Whether the model is saved during training (using the ModelCheckpoint callback) or only once training terminates. Only relevant if filepath is set. save_weights_only = False : bool Whether only the weights of the model or the full model are saved. Only relevant if filepath is set. modelcheck_opts = {'save_best_only':True, 'verbose':1} : dict Dictionary of keyword arguments to be passed on to the ModelCheckpoint callback, if it is present. save_weights_only (see above) is included in this dictionary. All other arguments are the Keras defaults. patience = None : int The number of epochs with no improvement after which the training is stopped (using the EarlyStopping callback). If None then no early stopping is used. earlystop_opts = {'restore_best_weights':True, 'verbose':1} : dict Dictionary of keyword arguments to be passed on to the EarlyStopping callback, if it is present. patience (see above) is included in this dictionary. All other arguments are the Keras defaults. Flags name_layers = True : bool Whether to give the layers of the model explicit names or let them be named automatically. One reason to set this to False would be in order to use parts of this model in another model (all Keras layers in a model are required to have unique names). compile = True : bool Whether the model should be compiled or not. summary = True : bool Whether a summary should be printed or not. fit fit(X_train, Y_train, **kwargs) Train the model by fitting the provided training dataset and labels. Transparently calls the fit() method of the underlying model. Arguments X_train : numpy.ndarray The training dataset as an array of features for each sample. Y_train : numpy.ndarray The labels for the training dataset. May need to be one-hot encoded depending on the requirements of the underlying model (typically Keras models will use one-hot encoding whereas the linear model does not.) kwargs : dict Keyword arguments passed on to the fit method of the underlying model. Most relevant for neural network models, where the Keras model docs contain detailed information on the possible arguments. Returns Whatever the underlying model's fit() returns. predict predict(X_test, **kwargs) Evaluate the model on a dataset. Note that for the LinearClassifier this corresponds to the predict_proba method of the underlying scikit-learn model. Arguments X_test : numpy.ndarray The dataset to evaluate the model on. kwargs : dict Keyword arguments passed on to the underlying model when predicting on a dataset. Returns numpy.ndarray The value of the model on the input dataset. model model The underlying model held by this architecture. Note that accessing an attribute that the architecture does not have will resulting in attempting to retrieve the attribute from this model. This allows for interrogation of the EnergyFlow architecture in the same manner as the underlying model. Examples For neural network models: model.layers will return a list of the layers, where model is any EnergFlow neural network. For linear models: model.coef_ will return the coefficients, where model is any EnergyFlow LinearClassifier instance.","title":"Architectures"},{"location":"docs/archs/#efn","text":"Energy Flow Network (EFN) architecture. energyflow.archs.EFN(*args, **kwargs) See ArchBase for how to pass in hyperparameters as well as hyperparameters common to all EnergyFlow neural network models. Required EFN Hyperparameters input_dim : int The number of features for each particle. Phi_sizes (formerly ppm_sizes ) : { tuple , list } of int The sizes of the dense layers in the per-particle frontend module $\\Phi$. The last element will be the number of latent observables that the model defines. F_sizes (formerly dense_sizes ) : { tuple , list } of int The sizes of the dense layers in the backend module $F$. Default EFN Hyperparameters Phi_acts = 'relu' (formerly ppm_acts ) : { tuple , list } of str or Keras activation Activation functions(s) for the dense layers in the per-particle frontend module $\\Phi$. A single string or activation layer will apply the same activation to all layers. Keras advanced activation layers are also accepted, either as strings (which use the default arguments) or as Keras Layer instances. If passing a single Layer instance, be aware that this layer will be used for all activations and may introduce weight sharing (such as with PReLU ); it is recommended in this case to pass as many activations as there are layers in the model. See the Keras activations docs for more detail. F_acts = 'relu' (formerly dense_acts ) : { tuple , list } of str or Keras activation Activation functions(s) for the dense layers in the backend module $F$. A single string or activation layer will apply the same activation to all layers. Phi_k_inits = 'he_uniform' (formerly ppm_k_inits ) : { tuple , list } of str or Keras initializer Kernel initializers for the dense layers in the per-particle frontend module $\\Phi$. A single string will apply the same initializer to all layers. See the Keras initializer docs for more detail. F_k_inits = 'he_uniform' (formerly dense_k_inits ) : { tuple , list } of str or Keras initializer Kernel initializers for the dense layers in the backend module $F$. A single string will apply the same initializer to all layers. latent_dropout = 0 : float Dropout rates for the summation layer that defines the value of the latent observables on the inputs. See the Keras Dropout layer for more detail. F_dropouts = 0 (formerly dense_dropouts ) : { tuple , list } of float Dropout rates for the dense layers in the backend module $F$. A single float will apply the same dropout rate to all dense layers. mask_val = 0 : float The value for which particles with all features set equal to this value will be ignored. See the Keras Masking layer for more detail.","title":"EFN"},{"location":"docs/archs/#eval_filters","text":"eval_filters(patch, n=100, prune=True) Evaluates the latent space filters of this model on a patch of the two-dimensional geometric input space. Arguments patch : { tuple , list } of float Specifies the patch of the geometric input space to be evaluated. A list of length 4 is interpretted as [xmin, ymin, xmax, ymax] . Passing a single float R is equivalent to [-R,-R,R,R] . n : { tuple , list } of int The number of grid points on which to evaluate the filters. A list of length 2 is interpretted as [nx, ny] where nx is the number of points along the x (or first) dimension and ny is the number of points along the y (or second) dimension. prune : bool Whether to remove filters that are all zero (which happens sometimes due to dying ReLUs). Returns ( numpy.ndarray , numpy.ndarray , numpy.ndarray ) Returns three arrays, (X, Y, Z) , where X and Y have shape (nx, ny) and are arrays of the values of the geometric inputs in the specified patch. Z has shape (num_filters, nx, ny) and is the value of the different filters at each point.","title":"eval_filters"},{"location":"docs/archs/#inputs","text":"inputs List of input tensors to the model. EFNs have two input tensors: inputs[0] corresponds to the zs input and inputs[1] corresponds to the phats input.","title":"inputs"},{"location":"docs/archs/#weights","text":"weights Weight tensor for the model. This is the zs input where entries equal to mask_val have been set to zero.","title":"weights"},{"location":"docs/archs/#phi","text":"Phi List of tensors corresponding to the layers in the $\\Phi$ network.","title":"Phi"},{"location":"docs/archs/#latent","text":"latent List of tensors corresponding to the summation layer in the network, including any dropout layer if present.","title":"latent"},{"location":"docs/archs/#f","text":"F List of tensors corresponding to the layers in the $F$ network.","title":"F"},{"location":"docs/archs/#output","text":"output Output tensor for the model.","title":"output"},{"location":"docs/archs/#pfn","text":"Particle Flow Network (PFN) architecture. Accepts the same hyperparameters as the EFN . energyflow.archs.PFN(*args, **kwargs)","title":"PFN"},{"location":"docs/archs/#inputs_1","text":"inputs List of input tensors to the model. PFNs have one input tensor corresponding to the ps input.","title":"inputs"},{"location":"docs/archs/#weights_1","text":"weights Weight tensor for the model. A weight of 0 is assigned to any particle which has all features equal to mask_val , and 1 is assigned otherwise.","title":"weights"},{"location":"docs/archs/#phi_1","text":"Phi List of tensors corresponding to the layers in the $\\Phi$ network.","title":"Phi"},{"location":"docs/archs/#latent_1","text":"latent List of tensors corresponding to the summation layer in the network, including any dropout layer if present.","title":"latent"},{"location":"docs/archs/#f_1","text":"F List of tensors corresponding to the layers in the $F$ network.","title":"F"},{"location":"docs/archs/#output_1","text":"output Output tensor for the model.","title":"output"},{"location":"docs/archs/#cnn","text":"Convolutional Neural Network architecture. energyflow.archs.CNN(*args, **kwargs) See ArchBase for how to pass in hyperparameters as well as hyperparameters common to all EnergyFlow neural network models. Required CNN Hyperparameters input_shape : { tuple , list } of int The shape of a single jet image. Assuming that data_format is set to channels_first , this is (nb_chan,npix,npix) . filter_sizes : { tuple , list } of int The size of the filters, which are taken to be square, in each convolutional layer of the network. The length of the list will be the number of convolutional layers in the network. num_filters : { tuple , list } of int The number of filters in each convolutional layer. The length of num_filters must match that of filter_sizes . Default CNN Hyperparameters dense_sizes = None : { tuple , list } of int The sizes of the dense layer backend. A value of None is equivalent to an empty list. pool_sizes = None : { tuple , list } of int Size of maxpooling filter, taken to be a square. A value of None will not use maxpooling. conv_acts = 'relu' : { tuple , list } of str or Keras activation Activation function(s) for the conv layers. A single string or activation layer will apply the same activation to all conv layers. Keras advanced activation layers are also accepted, either as strings (which use the default arguments) or as Keras Layer instances. If passing a single Layer instance, be aware that this layer will be used for all activations and may introduce weight sharing (such as with PReLU ); it is recommended in this case to pass as many activations as there are layers in the model.See the Keras activations docs for more detail. dense_acts = 'relu' : { tuple , list } of str or Keras activation Activation functions(s) for the dense layers. A single string or activation layer will apply the same activation to all dense layers. conv_k_inits = 'he_uniform' : { tuple , list } of str or Keras initializer Kernel initializers for the convolutional layers. A single string will apply the same initializer to all layers. See the Keras initializer docs for more detail. dense_k_inits = 'he_uniform' : { tuple , list } of str or Keras initializer Kernel initializers for the dense layers. A single string will apply the same initializer to all layers. conv_dropouts = 0 : { tuple , list } of float Dropout rates for the convolutional layers. A single float will apply the same dropout rate to all conv layers. See the Keras Dropout layer for more detail. num_spatial2d_dropout = 0 : int The number of convolutional layers, starting from the beginning of the model, for which to apply SpatialDropout2D instead of Dropout. dense_dropouts = 0 : { tuple , list } of float Dropout rates for the dense layers. A single float will apply the same dropout rate to all dense layers. paddings = 'valid' : { tuple , list } of str Controls how the filters are convoled with the inputs. See the Keras Conv2D layer for more detail. data_format = 'channels_first' : { 'channels_first' , 'channels_last' } Sets which axis is expected to contain the different channels.","title":"CNN"},{"location":"docs/archs/#dnn","text":"Dense Neural Network architecture. energyflow.archs.DNN(*args, **kwargs) See ArchBase for how to pass in hyperparameters as well as hyperparameters common to all EnergyFlow neural network models. Required DNN Hyperparameters input_dim : int The number of inputs to the model. dense_sizes : { tuple , list } of int The number of nodes in the dense layers of the model. Default DNN Hyperparameters acts = 'relu' : { tuple , list } of str or Keras activation Activation functions(s) for the dense layers. A single string or activation layer will apply the same activation to all dense layers. Keras advanced activation layers are also accepted, either as strings (which use the default arguments) or as Keras Layer instances. If passing a single Layer instance, be aware that this layer will be used for all activations and may introduce weight sharing (such as with PReLU ); it is recommended in this case to pass as many activations as there are layers in the model.See the Keras activations docs for more detail. k_inits = 'he_uniform' : { tuple , list } of str or Keras initializer Kernel initializers for the dense layers. A single string will apply the same initializer to all layers. See the Keras initializer docs for more detail. dropouts = 0 : { tuple , list } of float Dropout rates for the dense layers. A single float will apply the same dropout rate to all layers. See the Keras Dropout layer for more detail. l2_regs = 0 : { tuple , list } of float $L_2$-regulatization strength for both the weights and biases of the dense layers. A single float will apply the same $L_2$-regulatization to all layers.","title":"DNN"},{"location":"docs/archs/#linearclassifier","text":"Linear classifier that can be either Fisher's linear discriminant or logistic regression. Relies on the scikit-learn implementations of these classifiers. energyflow.archs.LinearClassifier(*args, **kwargs) See ArchBase for how to pass in hyperparameters. Default Hyperparameters linclass_type = 'lda' : { 'lda' , 'lr' } Controls which type of linear classifier is used. 'lda' corresponds to LinearDisciminantAnalysis and 'lr' to Logistic Regression . If using 'lr' all arguments are passed on directly to the scikit-learn class. Linear Discriminant Analysis Hyperparameters solver = 'svd' : { 'svd' , 'lsqr' , 'eigen' } Which LDA solver to use. tol = 1e-12 : float Threshold used for rank estimation. Notably not a convergence parameter. Logistic Regression Hyperparameters LR_hps = {} : dict Dictionary of keyword arguments to pass on to the underlying LogisticRegression model.","title":"LinearClassifier"},{"location":"docs/archs/#archbase","text":"Base class for all architectures contained in EnergyFlow. The mechanism of specifying hyperparameters for all architectures is described here. Methods common to all architectures are documented here. Note that this class cannot be instantiated directly as it is an abstract base class. energyflow.archs.archbase.ArchBase(*args, **kwargs) Accepts arbitrary arguments. Positional arguments (if present) are dictionaries of hyperparameters, keyword arguments (if present) are hyperparameters directly. Keyword hyperparameters take precedence over positional hyperparameter dictionaries. Arguments *args : arbitrary positional arguments Each argument is a dictionary containing hyperparameter (name, value) pairs. *kwargs : arbitrary keyword arguments Hyperparameters as keyword arguments. Takes precedence over the positional arguments. Default NN Hyperparameters Common hyperparameters that apply to all architectures except for LinearClassifier . Compilation Options loss = 'categorical_crossentropy' : str The loss function to use for the model. See the Keras loss function docs for available loss functions. optimizer = 'adam' : Keras optimizer or str A Keras optimizer instance or a string referring to one (in which case the default arguments are used). metrics = ['accuracy'] : list of str The Keras metrics to apply to the model. compile_opts = {} : dict Dictionary of keyword arguments to be passed on to the compile method of the model. loss , optimizer , and metrics (see above) are included in this dictionary. All other values are the Keras defaults. Output Options output_dim = 2 : int The output dimension of the model. output_act = 'softmax' : str or Keras activation Activation function to apply to the output. Callback Options filepath = None : str The file path for where to save the model. If None then the model will not be saved. save_while_training = True : bool Whether the model is saved during training (using the ModelCheckpoint callback) or only once training terminates. Only relevant if filepath is set. save_weights_only = False : bool Whether only the weights of the model or the full model are saved. Only relevant if filepath is set. modelcheck_opts = {'save_best_only':True, 'verbose':1} : dict Dictionary of keyword arguments to be passed on to the ModelCheckpoint callback, if it is present. save_weights_only (see above) is included in this dictionary. All other arguments are the Keras defaults. patience = None : int The number of epochs with no improvement after which the training is stopped (using the EarlyStopping callback). If None then no early stopping is used. earlystop_opts = {'restore_best_weights':True, 'verbose':1} : dict Dictionary of keyword arguments to be passed on to the EarlyStopping callback, if it is present. patience (see above) is included in this dictionary. All other arguments are the Keras defaults. Flags name_layers = True : bool Whether to give the layers of the model explicit names or let them be named automatically. One reason to set this to False would be in order to use parts of this model in another model (all Keras layers in a model are required to have unique names). compile = True : bool Whether the model should be compiled or not. summary = True : bool Whether a summary should be printed or not.","title":"ArchBase"},{"location":"docs/archs/#fit","text":"fit(X_train, Y_train, **kwargs) Train the model by fitting the provided training dataset and labels. Transparently calls the fit() method of the underlying model. Arguments X_train : numpy.ndarray The training dataset as an array of features for each sample. Y_train : numpy.ndarray The labels for the training dataset. May need to be one-hot encoded depending on the requirements of the underlying model (typically Keras models will use one-hot encoding whereas the linear model does not.) kwargs : dict Keyword arguments passed on to the fit method of the underlying model. Most relevant for neural network models, where the Keras model docs contain detailed information on the possible arguments. Returns Whatever the underlying model's fit() returns.","title":"fit"},{"location":"docs/archs/#predict","text":"predict(X_test, **kwargs) Evaluate the model on a dataset. Note that for the LinearClassifier this corresponds to the predict_proba method of the underlying scikit-learn model. Arguments X_test : numpy.ndarray The dataset to evaluate the model on. kwargs : dict Keyword arguments passed on to the underlying model when predicting on a dataset. Returns numpy.ndarray The value of the model on the input dataset.","title":"predict"},{"location":"docs/archs/#model","text":"model The underlying model held by this architecture. Note that accessing an attribute that the architecture does not have will resulting in attempting to retrieve the attribute from this model. This allows for interrogation of the EnergyFlow architecture in the same manner as the underlying model. Examples For neural network models: model.layers will return a list of the layers, where model is any EnergFlow neural network. For linear models: model.coef_ will return the coefficients, where model is any EnergyFlow LinearClassifier instance.","title":"model"},{"location":"docs/datasets/","text":"Quark and Gluon Jets A dataset consisting of up to 2 million total quark and gluon jets generated with PYTHIA 8.226. To avoid downloading unnecessary samples, the dataset is contained in twenty files with 100k jets each, and only the required files are downloaded. These samples are used in 1810.05165 . Splitting the data into 1.6M/200k/200k train/validation/test sets is recommended for standardized comparisons. The dataset qg_jets consists of two components: X : a three-dimensional numpy array of the jets with shape (num_data, max_num_particles, 4) y : a numpy array of quark/gluon jet labels (quark= 1 and gluon= 0 ). The jets are padded with zero-particles in order to make a contiguous array. The particles are given as (pt,y,phi,pid) values, where pid is the particle's PDG id . The samples are $Z(\\to\\nu\\bar\\nu)+g$ and $Z(\\to\\nu\\bar\\nu)+(u,d,s)$ events generated with PYTHIA for $pp$ collisions at $\\sqrt{s}=14$ TeV using the WeakBosonAndParton:qqbar2gmZg and WeakBosonAndParton:qg2gmZq processes, ignoring the photon contribution and requiring the $Z$ to decay invisibly to neutrinos. Hadronization and multiple parton interactions (i.e. underlying event) are turned on and the default tunings and shower parameters are used. Final state non-neutrino particles are clustered into $R=0.4$ anti-$k_T$ jets using FASTJET 3.3.0. Jets with transverse momentum $p_T\\in[500,550]$ GeV and rapidity $|y|<2.0$ are kept. Particles are ensured to have $\\phi$ values within $\\pi$ of the jet (i.e. no $\\phi$-periodicity issues). No detector simulation is performed. load energyflow.datasets.qg_jets.load(num_data=100000, pad=True, cache_dir=None) Loads samples from the dataset (which in total is contained in twenty files). Any file that is needed that has not been cached will be automatically downloaded. Downloading a file causes it to be cached for later use. Basic checksums are performed. Arguments num_data : int The number of events to return. A value of -1 means read in all events. pad : bool Whether to pad the events with zeros to make them the same length. cache_dir : str The directory where to store/look for the file. Returns 3-d numpy.ndarray , 1-d numpy.ndarray The X and y components of the dataset as specified above. Quark and Gluon Nsubs A dataset consisting of 45 $N$-subjettiness observables for 100k quark and gluon jets generated with Pythia 8.230. Following 1704.08249 , the observables are in the following order: \\{\\tau_1^{(\\beta=0.5)},\\tau_1^{(\\beta=1.0)},\\tau_1^{(\\beta=2.0)}, \\tau_2^{(\\beta=0.5)},\\tau_2^{(\\beta=1.0)},\\tau_2^{(\\beta=2.0)}, \\ldots, \\tau_{15}^{(\\beta=0.5)},\\tau_{15}^{(\\beta=1.0)},\\tau_{15}^{(\\beta=2.0)}\\}. The dataset contains two members: 'X' which is a numpy array of the nsubs that has shape (100000,45) and 'y' which is a numpy array of quark/gluon labels (quark= 1 and gluon= 0 ). load energyflow.datasets.qg_nsubs.load(num_data=-1, cache_dir=None) Loads the dataset. The first time this is called, it will automatically download the dataset. Future calls will attempt to use the cached dataset prior to redownloading. Arguments num_data : int The number of events to return. A value of -1 means read in all events. cache_dir : str The directory where to store/look for the file. Returns 3-d numpy.ndarray , 1-d numpy.ndarray The X and y components of the dataset as specified above.","title":"Datasets"},{"location":"docs/datasets/#quark-and-gluon-jets","text":"A dataset consisting of up to 2 million total quark and gluon jets generated with PYTHIA 8.226. To avoid downloading unnecessary samples, the dataset is contained in twenty files with 100k jets each, and only the required files are downloaded. These samples are used in 1810.05165 . Splitting the data into 1.6M/200k/200k train/validation/test sets is recommended for standardized comparisons. The dataset qg_jets consists of two components: X : a three-dimensional numpy array of the jets with shape (num_data, max_num_particles, 4) y : a numpy array of quark/gluon jet labels (quark= 1 and gluon= 0 ). The jets are padded with zero-particles in order to make a contiguous array. The particles are given as (pt,y,phi,pid) values, where pid is the particle's PDG id . The samples are $Z(\\to\\nu\\bar\\nu)+g$ and $Z(\\to\\nu\\bar\\nu)+(u,d,s)$ events generated with PYTHIA for $pp$ collisions at $\\sqrt{s}=14$ TeV using the WeakBosonAndParton:qqbar2gmZg and WeakBosonAndParton:qg2gmZq processes, ignoring the photon contribution and requiring the $Z$ to decay invisibly to neutrinos. Hadronization and multiple parton interactions (i.e. underlying event) are turned on and the default tunings and shower parameters are used. Final state non-neutrino particles are clustered into $R=0.4$ anti-$k_T$ jets using FASTJET 3.3.0. Jets with transverse momentum $p_T\\in[500,550]$ GeV and rapidity $|y|<2.0$ are kept. Particles are ensured to have $\\phi$ values within $\\pi$ of the jet (i.e. no $\\phi$-periodicity issues). No detector simulation is performed.","title":"Quark and Gluon Jets"},{"location":"docs/datasets/#load","text":"energyflow.datasets.qg_jets.load(num_data=100000, pad=True, cache_dir=None) Loads samples from the dataset (which in total is contained in twenty files). Any file that is needed that has not been cached will be automatically downloaded. Downloading a file causes it to be cached for later use. Basic checksums are performed. Arguments num_data : int The number of events to return. A value of -1 means read in all events. pad : bool Whether to pad the events with zeros to make them the same length. cache_dir : str The directory where to store/look for the file. Returns 3-d numpy.ndarray , 1-d numpy.ndarray The X and y components of the dataset as specified above.","title":"load"},{"location":"docs/datasets/#quark-and-gluon-nsubs","text":"A dataset consisting of 45 $N$-subjettiness observables for 100k quark and gluon jets generated with Pythia 8.230. Following 1704.08249 , the observables are in the following order: \\{\\tau_1^{(\\beta=0.5)},\\tau_1^{(\\beta=1.0)},\\tau_1^{(\\beta=2.0)}, \\tau_2^{(\\beta=0.5)},\\tau_2^{(\\beta=1.0)},\\tau_2^{(\\beta=2.0)}, \\ldots, \\tau_{15}^{(\\beta=0.5)},\\tau_{15}^{(\\beta=1.0)},\\tau_{15}^{(\\beta=2.0)}\\}. The dataset contains two members: 'X' which is a numpy array of the nsubs that has shape (100000,45) and 'y' which is a numpy array of quark/gluon labels (quark= 1 and gluon= 0 ).","title":"Quark and Gluon Nsubs"},{"location":"docs/datasets/#load_1","text":"energyflow.datasets.qg_nsubs.load(num_data=-1, cache_dir=None) Loads the dataset. The first time this is called, it will automatically download the dataset. Future calls will attempt to use the cached dataset prior to redownloading. Arguments num_data : int The number of events to return. A value of -1 means read in all events. cache_dir : str The directory where to store/look for the file. Returns 3-d numpy.ndarray , 1-d numpy.ndarray The X and y components of the dataset as specified above.","title":"load"},{"location":"docs/efps/","text":"The Energy Flow Polynomials (EFPs) are a set of observables, indexed by non-isomorphic multigraphs, which linearly span the space of infrared and collinear safe (IRC-safe) observables. An EFP, indexed by a multigraph $G$, takes the following form: \\text{EFP}_G=\\sum_{i_1=1}^M\\cdots\\sum_{i_N=1}^Mz_{i_1}\\cdots z_{i_N} \\prod_{(k,\\ell)\\in G}\\theta_{i_ki_\\ell} where $z_i$ is a measure of the energy of particle $i$ and $\\theta_{ij}$ is a measure of the angular separation between particles $i$ and $j$. The specific choices for \"energy\" and \"angular\" measure depend on the collider context and are discussed in the Measures section. EFP A class for representing and computing a single EFP. Note that all keyword arguments are stored as properties of the EFP instance. energyflow.EFP(edges, measure='hadr', beta=1, kappa=1, normed=True, coords=None, check_input=True, np_optimize='greedy') Arguments edges : list Edges of the EFP graph specified by pairs of vertices. measure : { 'hadr' , 'hadrdot' , 'ee' } The choice of measure. See Measures for additional info. beta : float The parameter $\\beta$ appearing in the measure. Must be greater than zero. kappa : { float , 'pf' } If a number, the energy weighting parameter $\\kappa$. If 'pf' , use $\\kappa=v-1$ where $v$ is the valency of the vertex. normed : bool Controls normalization of the energies in the measure. coords : { 'ptyphim' , 'epxpypz' , None } Controls which coordinates are assumed for the input. See Measures for additional info. check_input : bool Whether to check the type of the input each time or assume the first input type. np_optimize : { True , False , 'greedy' , 'optimal' } The optimize keyword of numpy.einsum_path . compute compute(event=None, zs=None, thetas=None) Computes the value of the EFP on a single event. Arguments event : 2-d array_like or fastjet.PseudoJet The event as an array of particles in the coordinates specified by coords . zs : 1-d array_like If present, thetas must also be present, and zs is used in place of the energies of an event. thetas : 2-d array_like If present, zs must also be present, and thetas is used in place of the pairwise angles of an event. Returns float The EFP value. batch_compute batch_compute(events, n_jobs=None) Computes the value of the EFP on several events. Arguments events : array_like or fastjet.PseudoJet The events as an array of arrays of particles in coordinates matching those anticipated by coords . n_jobs : int or None The number of worker processes to use. A value of None will use as many processes as there are CPUs on the machine. Returns 1-d numpy.ndarray A vector of the EFP value for each event. graph graph Graph of this EFP represented by a list of edges. simple_graph simple_graph Simple graph of this EFP (forgetting all multiedges) represented by a list of edges. n n Number of vertices in the graph of this EFP. d d Degree, or number of edges, in the graph of this EFP. c c VE complexity $\\chi$ of this EFP. EFPSet A class that holds a collection of EFPs and computes their values on events. Note that all keyword arguments are stored as properties of the EFPSet instance. energyflow.EFPSet(*args, filename=None, measure='hadr', beta=1, kappa=1, normed=True, coords='ptyphim', check_input=True, verbose=False) EFPSet can be initialized in one of three ways (in order of precedence): Default - Use the ($d\\le10$) EFPs that come installed with the EnergFlow package. Generator - Pass in a custom Generator object as the first positional argument. Custom File - Pass in the name of a .npz file saved with a custom Generator . To control which EFPs are included, EFPSet accepts an arbitrary number of specifications (see sel ) and only EFPs meeting each specification are included in the set. Arguments *args : arbitrary positional arguments If the first positional argument is a Generator instance, it is used for initialization. The remaining positional arguments must be valid arguments to sel . filename : string Path to a .npz file which has been saved by a valid energyflow.Generator . measure : { 'hadr' , 'hadr-dot' , 'ee' } See Measures for additional info. beta : float The parameter $\\beta$ appearing in the measure. Must be greater than zero. kappa : { float , 'pf' } If a number, the energy weighting parameter $\\kappa$. If 'pf' , use $\\kappa=v-1$ where $v$ is the valency of the vertex. normed : bool Controls normalization of the energies in the measure. coords : { 'ptyphim' , 'epxpypz' , None } Controls which coordinates are assumed for the input. See Measures for additional info. check_input : bool Whether to check the type of the input each time or assume the first input type. verbose : bool Controls printed output when initializing EFPSet. compute compute(event=None, zs=None, thetas=None) Computes the values of the stored EFPs on a single event. Arguments event : 2-d array_like or fastjet.PseudoJet The event as an array of particles in the coordinates specified by coords . zs : 1-d array_like If present, thetas must also be present, and zs is used in place of the energies of an event. thetas : 2-d array_like If present, zs must also be present, and thetas is used in place of the pairwise angles of an event. Returns 1-d numpy.ndarray A vector of the EFP values. batch_compute batch_compute(events, n_jobs=None) Computes the value of the stored EFPs on several events. Arguments events : array_like or fastjet.PseudoJet The events as an array of arrays of particles in coordinates matching those anticipated by coords . n_jobs : int or None The number of worker processes to use. A value of None will attempt to use as many processes as there are CPUs on the machine. Returns 2-d numpy.ndarray An array of the EFP values for each event. calc_disc calc_disc(X) Computes disconnected EFPs according to the internal specifications using the connected EFPs provided as input. Arguments X : numpy.ndarray Array of connected EFPs. Rows are different events, columns are the different EFPs. Can handle a single event (a 1-dim array) as input. EFPs are assumed to be in the order expected by the instance of EFPSet ; the safest way to ensure this is to use the same EFPSet to calculate both connected and disconnected EFPs. This function is used internally in compute and batch_compute . Returns numpy.ndarray A concatenated array of the connected and disconnected EFPs. sel sel(*args) Computes a boolean mask of EFPs matching each of the specifications provided by the args . Arguments *args : arbitrary positional arguments Each argument can be either a string or a length-two iterable. If the argument is a string, it should consist of three parts: a character which is a valid element of cols , a comparison operator (one of < , > , <= , >= , == , != ), and a number. Whitespace between the parts does not matter. If the argument is a tuple, the first element should be a string containing a column header character and a comparison operator; the second element is the value to be compared. The tuple version is useful when the value is a variable that changes (such as in a list comprehension). Returns 1-d numpy.ndarray A boolean array of length the number of EFPs stored by this object. count count(*args) Counts the number of EFPs meeting the specifications of the arguments using sel . Arguments *args : arbitrary positional arguments Valid arguments to be passed to sel . Returns int The number of EFPs meeting the specifications provided. graphs graphs(*args) Graphs meeting provided specifications. Arguments *args : arbitrary positional arguments Valid arguments to be passed to sel , or, if a single integer, the index of a particular graph. Returns list , if single integer argument is given The list of edges corresponding to the specified graph 1-d numpy.ndarray , otherwise An array of graphs (as lists of edges) matching the specifications. simple_graphs simple_graphs(*args) Simple graphs meeting provided specifications. Arguments *args : arbitrary positional arguments Valid arguments to be passed to sel , or, if a single integer, the index of particular simple graph. Returns list , if single integer argument is given The list of edges corresponding to the specified simple graph 1-d numpy.ndarray , otherwise An array of simple graphs (as lists of edges) matching the specifications. specs specs An array of EFP specifications. Each row represents an EFP and the columns represent the quantities indicated by cols . cspecs cspecs Specification array for connected EFPs. cols cols Column labels for specs . Those of primary interest are listed below. n : Number of vertices. e : Number of simple edges. d : Degree, or number of multiedges. v : Maximum valency (number of edges touching a vertex). k : Unique identifier within EFPs of this (n,d). c : VE complexity $\\chi$. p : Number of prime factors (or connected components). h : Number of valency 1 vertices (a.k.a. 'hanging chads').","title":"Energy Flow Polynomials"},{"location":"docs/efps/#efp","text":"A class for representing and computing a single EFP. Note that all keyword arguments are stored as properties of the EFP instance. energyflow.EFP(edges, measure='hadr', beta=1, kappa=1, normed=True, coords=None, check_input=True, np_optimize='greedy') Arguments edges : list Edges of the EFP graph specified by pairs of vertices. measure : { 'hadr' , 'hadrdot' , 'ee' } The choice of measure. See Measures for additional info. beta : float The parameter $\\beta$ appearing in the measure. Must be greater than zero. kappa : { float , 'pf' } If a number, the energy weighting parameter $\\kappa$. If 'pf' , use $\\kappa=v-1$ where $v$ is the valency of the vertex. normed : bool Controls normalization of the energies in the measure. coords : { 'ptyphim' , 'epxpypz' , None } Controls which coordinates are assumed for the input. See Measures for additional info. check_input : bool Whether to check the type of the input each time or assume the first input type. np_optimize : { True , False , 'greedy' , 'optimal' } The optimize keyword of numpy.einsum_path .","title":"EFP"},{"location":"docs/efps/#compute","text":"compute(event=None, zs=None, thetas=None) Computes the value of the EFP on a single event. Arguments event : 2-d array_like or fastjet.PseudoJet The event as an array of particles in the coordinates specified by coords . zs : 1-d array_like If present, thetas must also be present, and zs is used in place of the energies of an event. thetas : 2-d array_like If present, zs must also be present, and thetas is used in place of the pairwise angles of an event. Returns float The EFP value.","title":"compute"},{"location":"docs/efps/#batch_compute","text":"batch_compute(events, n_jobs=None) Computes the value of the EFP on several events. Arguments events : array_like or fastjet.PseudoJet The events as an array of arrays of particles in coordinates matching those anticipated by coords . n_jobs : int or None The number of worker processes to use. A value of None will use as many processes as there are CPUs on the machine. Returns 1-d numpy.ndarray A vector of the EFP value for each event.","title":"batch_compute"},{"location":"docs/efps/#graph","text":"graph Graph of this EFP represented by a list of edges.","title":"graph"},{"location":"docs/efps/#simple_graph","text":"simple_graph Simple graph of this EFP (forgetting all multiedges) represented by a list of edges.","title":"simple_graph"},{"location":"docs/efps/#n","text":"n Number of vertices in the graph of this EFP.","title":"n"},{"location":"docs/efps/#d","text":"d Degree, or number of edges, in the graph of this EFP.","title":"d"},{"location":"docs/efps/#c","text":"c VE complexity $\\chi$ of this EFP.","title":"c"},{"location":"docs/efps/#efpset","text":"A class that holds a collection of EFPs and computes their values on events. Note that all keyword arguments are stored as properties of the EFPSet instance. energyflow.EFPSet(*args, filename=None, measure='hadr', beta=1, kappa=1, normed=True, coords='ptyphim', check_input=True, verbose=False) EFPSet can be initialized in one of three ways (in order of precedence): Default - Use the ($d\\le10$) EFPs that come installed with the EnergFlow package. Generator - Pass in a custom Generator object as the first positional argument. Custom File - Pass in the name of a .npz file saved with a custom Generator . To control which EFPs are included, EFPSet accepts an arbitrary number of specifications (see sel ) and only EFPs meeting each specification are included in the set. Arguments *args : arbitrary positional arguments If the first positional argument is a Generator instance, it is used for initialization. The remaining positional arguments must be valid arguments to sel . filename : string Path to a .npz file which has been saved by a valid energyflow.Generator . measure : { 'hadr' , 'hadr-dot' , 'ee' } See Measures for additional info. beta : float The parameter $\\beta$ appearing in the measure. Must be greater than zero. kappa : { float , 'pf' } If a number, the energy weighting parameter $\\kappa$. If 'pf' , use $\\kappa=v-1$ where $v$ is the valency of the vertex. normed : bool Controls normalization of the energies in the measure. coords : { 'ptyphim' , 'epxpypz' , None } Controls which coordinates are assumed for the input. See Measures for additional info. check_input : bool Whether to check the type of the input each time or assume the first input type. verbose : bool Controls printed output when initializing EFPSet.","title":"EFPSet"},{"location":"docs/efps/#compute_1","text":"compute(event=None, zs=None, thetas=None) Computes the values of the stored EFPs on a single event. Arguments event : 2-d array_like or fastjet.PseudoJet The event as an array of particles in the coordinates specified by coords . zs : 1-d array_like If present, thetas must also be present, and zs is used in place of the energies of an event. thetas : 2-d array_like If present, zs must also be present, and thetas is used in place of the pairwise angles of an event. Returns 1-d numpy.ndarray A vector of the EFP values.","title":"compute"},{"location":"docs/efps/#batch_compute_1","text":"batch_compute(events, n_jobs=None) Computes the value of the stored EFPs on several events. Arguments events : array_like or fastjet.PseudoJet The events as an array of arrays of particles in coordinates matching those anticipated by coords . n_jobs : int or None The number of worker processes to use. A value of None will attempt to use as many processes as there are CPUs on the machine. Returns 2-d numpy.ndarray An array of the EFP values for each event.","title":"batch_compute"},{"location":"docs/efps/#calc_disc","text":"calc_disc(X) Computes disconnected EFPs according to the internal specifications using the connected EFPs provided as input. Arguments X : numpy.ndarray Array of connected EFPs. Rows are different events, columns are the different EFPs. Can handle a single event (a 1-dim array) as input. EFPs are assumed to be in the order expected by the instance of EFPSet ; the safest way to ensure this is to use the same EFPSet to calculate both connected and disconnected EFPs. This function is used internally in compute and batch_compute . Returns numpy.ndarray A concatenated array of the connected and disconnected EFPs.","title":"calc_disc"},{"location":"docs/efps/#sel","text":"sel(*args) Computes a boolean mask of EFPs matching each of the specifications provided by the args . Arguments *args : arbitrary positional arguments Each argument can be either a string or a length-two iterable. If the argument is a string, it should consist of three parts: a character which is a valid element of cols , a comparison operator (one of < , > , <= , >= , == , != ), and a number. Whitespace between the parts does not matter. If the argument is a tuple, the first element should be a string containing a column header character and a comparison operator; the second element is the value to be compared. The tuple version is useful when the value is a variable that changes (such as in a list comprehension). Returns 1-d numpy.ndarray A boolean array of length the number of EFPs stored by this object.","title":"sel"},{"location":"docs/efps/#count","text":"count(*args) Counts the number of EFPs meeting the specifications of the arguments using sel . Arguments *args : arbitrary positional arguments Valid arguments to be passed to sel . Returns int The number of EFPs meeting the specifications provided.","title":"count"},{"location":"docs/efps/#graphs","text":"graphs(*args) Graphs meeting provided specifications. Arguments *args : arbitrary positional arguments Valid arguments to be passed to sel , or, if a single integer, the index of a particular graph. Returns list , if single integer argument is given The list of edges corresponding to the specified graph 1-d numpy.ndarray , otherwise An array of graphs (as lists of edges) matching the specifications.","title":"graphs"},{"location":"docs/efps/#simple_graphs","text":"simple_graphs(*args) Simple graphs meeting provided specifications. Arguments *args : arbitrary positional arguments Valid arguments to be passed to sel , or, if a single integer, the index of particular simple graph. Returns list , if single integer argument is given The list of edges corresponding to the specified simple graph 1-d numpy.ndarray , otherwise An array of simple graphs (as lists of edges) matching the specifications.","title":"simple_graphs"},{"location":"docs/efps/#specs","text":"specs An array of EFP specifications. Each row represents an EFP and the columns represent the quantities indicated by cols .","title":"specs"},{"location":"docs/efps/#cspecs","text":"cspecs Specification array for connected EFPs.","title":"cspecs"},{"location":"docs/efps/#cols","text":"cols Column labels for specs . Those of primary interest are listed below. n : Number of vertices. e : Number of simple edges. d : Degree, or number of multiedges. v : Maximum valency (number of edges touching a vertex). k : Unique identifier within EFPs of this (n,d). c : VE complexity $\\chi$. p : Number of prime factors (or connected components). h : Number of valency 1 vertices (a.k.a. 'hanging chads').","title":"cols"},{"location":"docs/emd/","text":"The Energy Mover's Distance (EMD), also known as the Earth Mover's Distance, is a metric between particle collider events introduced in 1902.02346 . This submodule contains convenient functions for computing EMDs between individual events and collections of events. The core of the computation is done using the Python Optimal Transport (POT) library, which must be installed in order to use this submodule. From Eq. 1 in 1902.02346 , the EMD between two events is the minimum ''work'' required to rearrange one event $\\mathcal E$ into the other $\\mathcal E'$ by movements of energy $f_{ij}$ from particle $i$ in one event to particle $j$ in the other: \\text{EMD}(\\mathcal E,\\mathcal E^\\prime)=\\min_{\\{f_{ij}\\}}\\sum_{ij}f_{ij}\\frac{ \\theta_{ij}}{R} + \\left|\\sum_iE_i-\\sum_jE^\\prime_j\\right|,\\\\ f_{ij}\\ge 0, \\quad \\sum_jf_{ij}\\le E_i, \\quad \\sum_if_{ij}\\le E^\\prime_j, \\quad \\sum_{ij}f_{ij}=E_\\text{min}, where $E_i,E^\\prime_j$ are the energies of the particles in the two events, $\\theta_{ij}$ is an angular distance between particles, and $E_\\text{min}=\\min\\left(\\sum_iE_i,\\,\\sum_jE^\\prime_j\\right)$ is the smaller of the two total energies. In a hadronic context, transverse momenta are used instead of energies. emd energyflow.emd.emd(ev0, ev1, R=1.0, norm=False, return_flow=False, gdim=2, n_iter_max=100000, periodic_phi=False, phi_col=2) Compute the EMD between two events. Arguments ev0 : numpy.ndarray The first event, given as a two-dimensional array. The event is assumed to be an (M,1+gdim) array of particles, where M is the multiplicity and gdim is the dimension of the ground space in which to compute euclidean distances between particles (as specified by the gdim keyword argument. The zeroth column is assumed to be the energies (or equivalently, the transverse momenta) of the particles. For typical hadron collider jet applications, each particle will be of the form (pT,y,phi) where y is the rapidity and phi is the azimuthal angle. ev1 : numpy.ndarray The other event, same format as ev0 . R : float The R parameter in the EMD definition that controls the relative importance of the two terms. Must be greater than or equal to half of the maximum ground distance in the space in order for the EMD to be a valid metric. norm : bool Whether or not to normalize the pT values of the events prior to computing the EMD. return_flow : bool Whether or not to return the flow matrix describing the optimal transport found during the computation of the EMD. Note that since the second term in Eq. 1 is implemented by including an additional particle in the event with lesser total pT, this will be reflected in the flow matrix. gdim : int The dimension of the ground metric space. Useful for restricting which dimensions are considered part of the ground space. Can be larger than the number of dimensions present in the events (in which case all dimensions will be included). n_iter_max : int Maximum number of iterations for solving the optimal transport problem. periodic_phi : bool Whether to expect (and therefore properly handle) periodicity in the coordinate corresponding to the azimuthal angle $\\phi$. Should typically be True for event-level applications but can be set to False (which is slightly faster) for jet applications where all $\\phi$ differences are less than or equal to $\\pi$. phi_col : int The index of the column of $\\phi$ values in the event array. Returns float The EMD value. [ numpy.ndarray ], optional The flow matrix found while solving for the EMD. The (i,j) th entry is the amount of pT that flows between particle i in ev0 and particle j in ev1 . emds energyflow.emd.emds(X0, X1=None, R=1.0, norm=False, gdim=2, n_iter_max=100000, periodic_phi=False, phi_col=2, n_jobs=None, verbose=0, print_every=1000000) Compute the EMD between collections of events. This can be used to compute EMDs between all pairs of events in a set or between events in two difference sets. Arguments X0 : list Iterable collection of events. Each event is assumed to be an (M,1+gdim) array of particles, where M is the multiplicity and gdim is the dimension of the ground space in which to compute euclidean distances between particles (specified by the gdim keyword argument). The zeroth column is assumed to be the energies (or equivalently, the transverse momenta) of the particles. For typical hadron collider jet applications, each particle will be of the form (pT,y,phi) where y is the rapidity and phi is the azimuthal angle. X1 : list or None Iterable collection of events in the same format as X0 , or None . If the latter, the pairwise distances between events in X0 will be computed and the returned matrix will be symmetric. R : float The R parameter in the EMD definition that controls the relative importance of the two terms. Must be greater than or equal to half of the maximum ground distance in the space in order for the EMD to be a valid metric. norm : bool Whether or not to normalize the pT values of the events prior to computing the EMD. gdim : int The dimension of the ground metric space. Useful for restricting which dimensions are considered part of the ground space. Can be larger than the number of dimensions present in the events (in which case all dimensions will be included). n_iter_max : int Maximum number of iterations for solving the optimal transport problem. periodic_phi : bool Whether to expect (and therefore properly handle) periodicity in the coordinate corresponding to the azimuthal angle $\\phi$. Should typically be True for event-level applications but can be set to False (which is slightly faster) for jet applications where all $\\phi$ differences are less than or equal to $\\pi$. phi_col : int The index of the column of $\\phi$ values in the event array. n_jobs : int or None The number of worker processes to use. A value of None will use as many processes as there are CPUs on the machine. Note that for smaller numbers of events, a smaller value of n_jobs can be faster. verbose : int Controls the verbosity level. A value greater than 0 will print the progress of the computation at intervals specified by print_every . print_every : int The number of computations to do in between printing the progress. Even if the verbosity level is zero, this still plays a role in determining when the worker processes report the results back to the main process. Returns numpy.ndarray The EMD values as a two-dimensional array. If X1 was None , then the shape will be (len(X0), len(X0)) and the array will be symmetric, otherwise it will have shape (len(X0), len(X1)) .","title":"EMD"},{"location":"docs/emd/#emd","text":"energyflow.emd.emd(ev0, ev1, R=1.0, norm=False, return_flow=False, gdim=2, n_iter_max=100000, periodic_phi=False, phi_col=2) Compute the EMD between two events. Arguments ev0 : numpy.ndarray The first event, given as a two-dimensional array. The event is assumed to be an (M,1+gdim) array of particles, where M is the multiplicity and gdim is the dimension of the ground space in which to compute euclidean distances between particles (as specified by the gdim keyword argument. The zeroth column is assumed to be the energies (or equivalently, the transverse momenta) of the particles. For typical hadron collider jet applications, each particle will be of the form (pT,y,phi) where y is the rapidity and phi is the azimuthal angle. ev1 : numpy.ndarray The other event, same format as ev0 . R : float The R parameter in the EMD definition that controls the relative importance of the two terms. Must be greater than or equal to half of the maximum ground distance in the space in order for the EMD to be a valid metric. norm : bool Whether or not to normalize the pT values of the events prior to computing the EMD. return_flow : bool Whether or not to return the flow matrix describing the optimal transport found during the computation of the EMD. Note that since the second term in Eq. 1 is implemented by including an additional particle in the event with lesser total pT, this will be reflected in the flow matrix. gdim : int The dimension of the ground metric space. Useful for restricting which dimensions are considered part of the ground space. Can be larger than the number of dimensions present in the events (in which case all dimensions will be included). n_iter_max : int Maximum number of iterations for solving the optimal transport problem. periodic_phi : bool Whether to expect (and therefore properly handle) periodicity in the coordinate corresponding to the azimuthal angle $\\phi$. Should typically be True for event-level applications but can be set to False (which is slightly faster) for jet applications where all $\\phi$ differences are less than or equal to $\\pi$. phi_col : int The index of the column of $\\phi$ values in the event array. Returns float The EMD value. [ numpy.ndarray ], optional The flow matrix found while solving for the EMD. The (i,j) th entry is the amount of pT that flows between particle i in ev0 and particle j in ev1 .","title":"emd"},{"location":"docs/emd/#emds","text":"energyflow.emd.emds(X0, X1=None, R=1.0, norm=False, gdim=2, n_iter_max=100000, periodic_phi=False, phi_col=2, n_jobs=None, verbose=0, print_every=1000000) Compute the EMD between collections of events. This can be used to compute EMDs between all pairs of events in a set or between events in two difference sets. Arguments X0 : list Iterable collection of events. Each event is assumed to be an (M,1+gdim) array of particles, where M is the multiplicity and gdim is the dimension of the ground space in which to compute euclidean distances between particles (specified by the gdim keyword argument). The zeroth column is assumed to be the energies (or equivalently, the transverse momenta) of the particles. For typical hadron collider jet applications, each particle will be of the form (pT,y,phi) where y is the rapidity and phi is the azimuthal angle. X1 : list or None Iterable collection of events in the same format as X0 , or None . If the latter, the pairwise distances between events in X0 will be computed and the returned matrix will be symmetric. R : float The R parameter in the EMD definition that controls the relative importance of the two terms. Must be greater than or equal to half of the maximum ground distance in the space in order for the EMD to be a valid metric. norm : bool Whether or not to normalize the pT values of the events prior to computing the EMD. gdim : int The dimension of the ground metric space. Useful for restricting which dimensions are considered part of the ground space. Can be larger than the number of dimensions present in the events (in which case all dimensions will be included). n_iter_max : int Maximum number of iterations for solving the optimal transport problem. periodic_phi : bool Whether to expect (and therefore properly handle) periodicity in the coordinate corresponding to the azimuthal angle $\\phi$. Should typically be True for event-level applications but can be set to False (which is slightly faster) for jet applications where all $\\phi$ differences are less than or equal to $\\pi$. phi_col : int The index of the column of $\\phi$ values in the event array. n_jobs : int or None The number of worker processes to use. A value of None will use as many processes as there are CPUs on the machine. Note that for smaller numbers of events, a smaller value of n_jobs can be faster. verbose : int Controls the verbosity level. A value greater than 0 will print the progress of the computation at intervals specified by print_every . print_every : int The number of computations to do in between printing the progress. Even if the verbosity level is zero, this still plays a role in determining when the worker processes report the results back to the main process. Returns numpy.ndarray The EMD values as a two-dimensional array. If X1 was None , then the shape will be (len(X0), len(X0)) and the array will be symmetric, otherwise it will have shape (len(X0), len(X1)) .","title":"emds"},{"location":"docs/gen/","text":"Implementation of EFP Generator class. Generator Generates non-isomorphic multigraphs according to provided specifications. energyflow.Generator(dmax=None, nmax=None, emax=None, cmax=None, vmax=None, comp_dmaxs=None, filename=None, np_optimize='greedy', verbose=False) Doing a fresh generation of connected multigraphs ( filename=None ) requires that igraph be installed. Arguments dmax : int The maximum number of edges of the generated connected graphs. nmax : int The maximum number of vertices of the generated connected graphs. emax : int The maximum number of edges of the generated connected simple graphs. cmax : int The maximum VE complexity $\\chi$ of the generated connected graphs. vmax : int The maximum valency of the generated connected graphs. comp_dmaxs : { dict , int } If an integer, the maximum number of edges of the generated disconnected graphs. If a dictionary, the keys are numbers of vertices and the values are the maximum number of edges of the generated disconnected graphs with that number of vertices. filename : str If None , do a complete generation from scratch. If set to a string, read in connected graphs from the file given, restrict them according to the various 'max' parameters, and do a fresh disconnected generation. The special value filename='default' means to read in graphs from the default file. This is useful when various disconnected graph parameters are to be varied since the generation of large simple graphs is the most computationlly intensive part. np_optimize : { True , False , 'greedy' , 'optimal' } The optimize keyword of numpy.einsum_path . verbose : bool A flag to control printing. save save(filename) Save the current generator to file. Arguments filename : str The path to save the file. specs specs An array of EFP specifications. Each row represents an EFP and the columns represent the quantities indicated by cols .","title":"Multigraph Generation"},{"location":"docs/gen/#generator","text":"Generates non-isomorphic multigraphs according to provided specifications. energyflow.Generator(dmax=None, nmax=None, emax=None, cmax=None, vmax=None, comp_dmaxs=None, filename=None, np_optimize='greedy', verbose=False) Doing a fresh generation of connected multigraphs ( filename=None ) requires that igraph be installed. Arguments dmax : int The maximum number of edges of the generated connected graphs. nmax : int The maximum number of vertices of the generated connected graphs. emax : int The maximum number of edges of the generated connected simple graphs. cmax : int The maximum VE complexity $\\chi$ of the generated connected graphs. vmax : int The maximum valency of the generated connected graphs. comp_dmaxs : { dict , int } If an integer, the maximum number of edges of the generated disconnected graphs. If a dictionary, the keys are numbers of vertices and the values are the maximum number of edges of the generated disconnected graphs with that number of vertices. filename : str If None , do a complete generation from scratch. If set to a string, read in connected graphs from the file given, restrict them according to the various 'max' parameters, and do a fresh disconnected generation. The special value filename='default' means to read in graphs from the default file. This is useful when various disconnected graph parameters are to be varied since the generation of large simple graphs is the most computationlly intensive part. np_optimize : { True , False , 'greedy' , 'optimal' } The optimize keyword of numpy.einsum_path . verbose : bool A flag to control printing.","title":"Generator"},{"location":"docs/gen/#save","text":"save(filename) Save the current generator to file. Arguments filename : str The path to save the file.","title":"save"},{"location":"docs/gen/#specs","text":"specs An array of EFP specifications. Each row represents an EFP and the columns represent the quantities indicated by cols .","title":"specs"},{"location":"docs/measures/","text":"Energy and Angular Measures The appropriate notions of energy and angle depend on the collider context. Typically, one wants to work with observables that respect the appropriate Lorentz subgroup for the collision type of interest. EnergyFlow is capable of handling two broad classes of measures: $e^+e^-$ and hadronic, which are selected using the required measure argument. For substructure applications, it is often convenient to normalize the energies so that $\\sum_iz_i=1$. The normed keyword argument is provided to control normalization of the energies (default is True ). Each measure comes with a parameter $\\beta>0$ which controls the relative weighting between smaller and larger anglular structures. This can be set using the beta keyword argument (default is 1 ). There is also a $\\kappa$ parameter to control the relative weighting between soft and hard energies. This can be set using the kappa keyword argument (default is 1 ). Only kappa=1 yields collinear-safe observables. Beyond the measures implemented here, the user can implement their own custom measure by passing in ${z_i}$ and ${\\theta_{ij}}$ directly to the EFP classes. Hadronic Measures For hadronic collisions, observables are typically desired to be invariant under boosts along the beam direction and rotations about the beam direction. Thus, particle transverse momentum $p_T$ and rapidity-azimuth coordinates $(y,\\phi)$ are used. There are two hadronic measures implemented in EnergyFlow: 'hadr' and 'hadrdot' . These are listed explicitly below. 'hadr' : z_i=p_{T,i}^{\\kappa},\\quad\\quad \\theta_{ij}=(\\Delta y_{ij}^2 + \\Delta\\phi_{ij}^2)^{\\beta/2}. 'hadrdot' : z_i=p_{T,i}^{\\kappa},\\quad\\quad \\theta_{ij}=\\left(\\frac{2p^\\mu_ip_{j\\mu}}{p_{T,i}p_{T,j}} \\right)^{\\beta/2}. e+e- Measures For $e^+e^-$ collisions, observables are typically desired to be invariant under the full group of rotations about the interaction point. Since the center of momentum energy is known, the particle energy $E$ is typically used. For the angular measure, pairwise Lorentz contractions of the normalized particle four-momenta are used. There is one $e^+e^-$ measure implemented. 'ee' : z_i = E_{i}^{\\kappa}, \\quad\\quad \\theta_{ij} = \\left(\\frac{2p_i^\\mu p_{j \\mu}}{E_i E_j}\\right)^{\\beta/2}. Measure Class for dealing with any kind of measure. energyflow.Measure(measure, beta=1, kappa=1, normed=True, coords=None, check_input=True) Processes inputs according to the measure choice. Arguments measure : string The string specifying the energy and angular measures to use. beta : float The angular weighting exponent $\\beta$. Must be positive. kappa : { float , 'pf' } If a number, the energy weighting exponent $\\kappa$. If 'pf' , use $\\kappa=v$ where $v$ is the valency of the vertex. 'pf' cannot be used with measure 'hadr' . Only IRC-safe for kappa=1 . normed : bool Whether or not to use normalized energies. coords : { 'ptyphim' , 'epxpypz' , None } Controls which coordinates are assumed for the input. If 'ptyphim' , the fourth column (the masses) is optional and massless particles are assumed if it is not present. If None , coords with be 'ptyphim' if using a hadronic measure and 'epxpypz' if using the e+e- measure. check_input : bool Whether to check the type of input each time or assume the first input type. evaluate evaluate(arg) Evaluate the measure on a set of particles. Arguments arg : 2-d numpy.ndarray A two-dimensional array of the particles with each row being a particle and the columns specified by the coords attribute. Returns ( 1-d numpy.ndarray , 2-d numpy.ndarray ) ( zs , thetas ) where zs is a vector of the energy fractions for each particle and thetas is the distance matrix between the particles.","title":"Measures"},{"location":"docs/measures/#energy-and-angular-measures","text":"The appropriate notions of energy and angle depend on the collider context. Typically, one wants to work with observables that respect the appropriate Lorentz subgroup for the collision type of interest. EnergyFlow is capable of handling two broad classes of measures: $e^+e^-$ and hadronic, which are selected using the required measure argument. For substructure applications, it is often convenient to normalize the energies so that $\\sum_iz_i=1$. The normed keyword argument is provided to control normalization of the energies (default is True ). Each measure comes with a parameter $\\beta>0$ which controls the relative weighting between smaller and larger anglular structures. This can be set using the beta keyword argument (default is 1 ). There is also a $\\kappa$ parameter to control the relative weighting between soft and hard energies. This can be set using the kappa keyword argument (default is 1 ). Only kappa=1 yields collinear-safe observables. Beyond the measures implemented here, the user can implement their own custom measure by passing in ${z_i}$ and ${\\theta_{ij}}$ directly to the EFP classes.","title":"Energy and Angular Measures"},{"location":"docs/measures/#hadronic-measures","text":"For hadronic collisions, observables are typically desired to be invariant under boosts along the beam direction and rotations about the beam direction. Thus, particle transverse momentum $p_T$ and rapidity-azimuth coordinates $(y,\\phi)$ are used. There are two hadronic measures implemented in EnergyFlow: 'hadr' and 'hadrdot' . These are listed explicitly below. 'hadr' : z_i=p_{T,i}^{\\kappa},\\quad\\quad \\theta_{ij}=(\\Delta y_{ij}^2 + \\Delta\\phi_{ij}^2)^{\\beta/2}. 'hadrdot' : z_i=p_{T,i}^{\\kappa},\\quad\\quad \\theta_{ij}=\\left(\\frac{2p^\\mu_ip_{j\\mu}}{p_{T,i}p_{T,j}} \\right)^{\\beta/2}.","title":"Hadronic Measures"},{"location":"docs/measures/#ee-measures","text":"For $e^+e^-$ collisions, observables are typically desired to be invariant under the full group of rotations about the interaction point. Since the center of momentum energy is known, the particle energy $E$ is typically used. For the angular measure, pairwise Lorentz contractions of the normalized particle four-momenta are used. There is one $e^+e^-$ measure implemented. 'ee' : z_i = E_{i}^{\\kappa}, \\quad\\quad \\theta_{ij} = \\left(\\frac{2p_i^\\mu p_{j \\mu}}{E_i E_j}\\right)^{\\beta/2}.","title":"e+e- Measures"},{"location":"docs/measures/#measure","text":"Class for dealing with any kind of measure. energyflow.Measure(measure, beta=1, kappa=1, normed=True, coords=None, check_input=True) Processes inputs according to the measure choice. Arguments measure : string The string specifying the energy and angular measures to use. beta : float The angular weighting exponent $\\beta$. Must be positive. kappa : { float , 'pf' } If a number, the energy weighting exponent $\\kappa$. If 'pf' , use $\\kappa=v$ where $v$ is the valency of the vertex. 'pf' cannot be used with measure 'hadr' . Only IRC-safe for kappa=1 . normed : bool Whether or not to use normalized energies. coords : { 'ptyphim' , 'epxpypz' , None } Controls which coordinates are assumed for the input. If 'ptyphim' , the fourth column (the masses) is optional and massless particles are assumed if it is not present. If None , coords with be 'ptyphim' if using a hadronic measure and 'epxpypz' if using the e+e- measure. check_input : bool Whether to check the type of input each time or assume the first input type.","title":"Measure"},{"location":"docs/measures/#evaluate","text":"evaluate(arg) Evaluate the measure on a set of particles. Arguments arg : 2-d numpy.ndarray A two-dimensional array of the particles with each row being a particle and the columns specified by the coords attribute. Returns ( 1-d numpy.ndarray , 2-d numpy.ndarray ) ( zs , thetas ) where zs is a vector of the energy fractions for each particle and thetas is the distance matrix between the particles.","title":"evaluate"},{"location":"docs/utils/","text":"Particle Tools Tools to compute particle kinematic quantities from four-vectors, such as transverse momentum $p_T$, rapidity $y$, and azimuthal angle $\\phi$, and vice versa. p4s_from_ptyphims energyflow.p4s_from_ptyphims(ptyphims) Calculate Euclidean four-vectors from transverse momentum, rapidity, azimuthal angle, and (optionally) mass for each input. Arguments ptyphims : numpy.ndarray or list An array with shape (M,4) of [pT,y,phi,m] for each particle. An array with shape (M,3) is also accepted where the masses are taken to be zero. A single particle is also accepted. Returns numpy.ndarray An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. If a single particle was given as input, a single four-vector will be returned. p4s_from_ptyphis energyflow.p4s_from_ptyphis(ptyphis) Legacy function : Will be removed in version 1.0. Use p4s_from_ptyphims for equivalent functionality. ptyphims_from_p4s energyflow.ptyphims_from_p4s(p4s, phi_ref=None, keep_allzeros=True) Compute the [pt,y,phi,m] representation of a four-vector for each Euclidean four-vector given as input. All-zero four-vectors are removed unless keep_shape is True . Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. phi_ref : float A reference value used so that all phis will be within $\\pm\\pi$ of this value. A value of None means that no phi fixing will be applied. keep_allzeros : bool Flag to determine if all-zero four-vectors will be retained as such. Otherwise, they are removed (resulting in a change in the shape of the output). Returns numpy.ndarray An array of size (M,4) consisting of the transverse momentum, rapidity, azimuthal angle, and mass of each particle. If a single particle was given as input, a one-dimensional array is returned. pts_from_p4s energyflow.pts_from_p4s(p4s) Calculate the transverse momenta of a collection of four-vectors Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. Returns numpy.ndarray An M -length array consisting of the transverse momentum of each particle. If a single particle was given as input, a single float is returned. ys_from_p4s energyflow.ys_from_p4s(p4s) Calculate the rapidities of a collection of four-vectors Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. Returns numpy.ndarray An M -length array consisting of the rapidity of each particle. If a single particle was given as input, a single float is returned. phis_from_p4s energyflow.phis_from_p4s(p4s, phi_ref=None) Calculate the azimuthal angles of a collection of four-vectors. If phi_ref is not None , then phi_fix is called using this value. Otherwise, the angles are chosen to be in the inverval $[0,2\\pi]$. Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. phi_ref : float See phi_fix Returns numpy.ndarray An M -length array consisting of the azimuthal angle of each particle. If a single particle was given as input, a single float is returned. ms_from_p4s energyflow.ms_from_p4s(p4s) Calculate the masses of a collection of four-vectors. Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. Returns numpy.ndarray An M -length array consisting of the mass of each particle. If a single particle was given as input, a single float is returned. phi_fix energyflow.phi_fix(phis, phi_ref, copy=False) A function to ensure that all phi values are within $\\pi$ of phi_ref . It is assumed that all starting phi values are within $2\\pi$ of phi_ref . Arguments phis : numpy.ndarray or list One-dimensional array of phi values. phi_ref : float A reference value used so that all phis will be within $\\pm\\pi$ of this value. copy : bool Determines if phis are copied or not. If False then phis may be modified in place. Returns numpy.ndarray An array of the fixed phi values. flat_metric energyflow.flat_metric(dim) The Minkowski metric in dim spacetime dimensions in the mostly-minus convention. Arguments dim : int The number of spacetime dimensions (thought to be four in our universe). Returns 1-d numpy.ndarray A dim -length, one-dimensional (not matrix) array equal to [+1,-1,...,-1] Random Events Functions to generate random sets of four-vectors. Includes an implementation of the RAMBO algorithm for sampling uniform M-body massless phase space. Also includes other functions for various random, non-center of momentum, and non-uniform sampling. gen_random_events energyflow.gen_random_events(nevents, nparticles, dim=4, mass=0) Generate random events with a given number of particles of a given mass in a given spacetime dimension. The spatial components of the momenta are distributed uniformly in $[-1,+1]$. These events are not guaranteed to uniformly sample phase space. Arguments nevents : int Number of events to generate. nparticles : int Number of particles in each event. dim : int Number of spacetime dimensions. mass : float Mass of the particles to generate. Returns numpy.ndarray An (nevents,nparticles,dim) array of events. The particles are specified as [E,p1,p2,...] . gen_random_events_mcom energyflow.gen_random_events_mcom(nevents, nparticles, dim=4) Generate random events with a given number of massless particles in a given spacetime dimension. The total energy and momentum are made to sum to zero by making about half of the particles incoming. These events are not guaranteed to uniformly sample phase space. Arguments nevents : int Number of events to generate. nparticles : int Number of particles in each event. dim : int Number of spacetime dimensions. Returns numpy.ndarray An (nevents,nparticles,dim) array of events. The particles are specified as [E,p1,p2,...] . gen_massless_phase_space energyflow.gen_massless_phase_space(nevents, nparticles, energy=1) Implementation of the RAMBO algorithm for uniformly sampling massless M-body phase space for any center of mass energy. Arguments nevents : int Number of events to generate. nparticles : int Number of particles in each event. energy : float Total center of mass energy of each event. Returns numpy.ndarray An (nevents,nparticles,4) array of events. The particles are specified as [E,p_x,p_y,p_z] . Data Tools Functions for dealing with datasets. These are not importable from the top level energyflow module, but must instead be imported from energyflow.utils . get_examples energyflow.utils.get_examples(path='~/.energyflow', which='all', overwrite=False) Pulls examples from GitHub. To ensure availability of all examples update EnergyFlow to the latest version. Arguments path : str The destination for the downloaded files. which : { list , 'all' } List of examples to download, or the string 'all' in which case all the available examples are downloaded. overwrite : bool Whether to overwrite existing files or not. data_split energyflow.utils.data_split(*args, train=-1, val=0.0, test=0.1, shuffle=True) A function to split a dataset into train, test, and optionally validation datasets. Arguments *args : arbitrary numpy.ndarray datasets An arbitrary number of datasets, each required to have the same number of elements, as numpy arrays. train : { int , float } If a float, the fraction of elements to include in the training set. If an integer, the number of elements to include in the training set. The value -1 is special and means include the remaining part of the dataset in the training dataset after the test and (optionally) val parts have been removed val : { int , float } If a float, the fraction of elements to include in the validation set. If an integer, the number of elements to include in the validation set. The value 0 is special and means do not form a validation set. test : { int , float } If a float, the fraction of elements to include in the test set. If an integer, the number of elements to include in the test set. shuffle : bool A flag to control whether the dataset is shuffle prior to being split into parts. Returns list A list of the split datasets in train, [val], test order. If datasets X , Y , and Z were given as args (and assuming a non-zero val ), then [ X_train , X_val , X_test , Y_train , Y_val , Y_test , Z_train , Z_val , Z_test ] will be returned. to_categorical energyflow.utils.to_categorical(labels, num_classes=None) One-hot encodes class labels. Arguments labels : 1-d numpy.ndarray Labels in the range [0,num_classes) . num_classes : { int , None } The total number of classes. If None , taken to be the maximum label plus one. Returns 2-d numpy.ndarray The one-hot encoded labels. remap_pids energyflow.utils.remap_pids(events, pid_i=3) Remaps PDG id numbers to small floats for use in a neural network. events are modified in place and nothing is returned. Arguments events : 3-d numpy.ndarray The events as an array of arrays of particles. pid_i : int The index corresponding to pid information along the last axis of events . Image Tools Functions for dealing with image representations of events. These are not importable from the top level energyflow module, but must instead be imported from energyflow.utils . pixelate energyflow.utils.pixelate(jet, npix=33, img_width=0.8, nb_chan=1, norm=True, charged_counts_only=False) A function for creating a jet image from an array of particles. Arguments jet : numpy.ndarray An array of particles where each particle is of the form [pt,y,phi,pid] where the particle id column is only used if nb_chan=2 and charged_counts_only=True . npix : int The number of pixels on one edge of the jet image, which is taken to be a square. img_width : float The size of one edge of the jet image in the rapidity-azimuth plane. nb_chan : { 1 , 2 } The number of channels in the jet image. If 1 , then only a $p_T$ channel is constructed (grayscale). If 2 , then both a $p_T$ channel and a count channel are formed (color). norm : bool Whether to normalize the $p_T$ pixels to sum to 1 . charged_counts_only : bool If making a count channel, whether to only include charged particles. Requires that pid information be given. Returns 3-d numpy.ndarray The jet image as a (nb_chan, npix, npix) array. standardize energyflow.utils.standardize(*args, channels=None, copy=False, reg=10**-10) Normalizes each argument by the standard deviation of the pixels in arg[0]. The expected use case would be standardize(X_train, X_val, X_test) . Arguments *args : arbitrary numpy.ndarray datasets An arbitrary number of datasets, each required to have the same shape in all but the first axis. channels : int A list of which channels (assumed to be the second axis) to standardize. None is interpretted to mean every channel. copy : bool Whether or not to copy the input arrays before modifying them. reg : float Small parameter used to avoid dividing by zero. It's important that this be kept consistent for images used with a given model. Returns list A list of the now-standardized arguments. zero_center energyflow.utils.zero_center(args, kwargs) Subtracts the mean of arg[0] from the arguments. The expected use case would be standardize(X_train, X_val, X_test) . Arguments *args : arbitrary numpy.ndarray datasets An arbitrary number of datasets, each required to have the same shape in all but the first axis. channels : int A list of which channels (assumed to be the second axis) to zero center. None is interpretted to mean every channel. copy : bool Whether or not to copy the input arrays before modifying them. Returns list A list of the zero-centered arguments.","title":"Utils"},{"location":"docs/utils/#particle-tools","text":"Tools to compute particle kinematic quantities from four-vectors, such as transverse momentum $p_T$, rapidity $y$, and azimuthal angle $\\phi$, and vice versa.","title":"Particle Tools"},{"location":"docs/utils/#p4s_from_ptyphims","text":"energyflow.p4s_from_ptyphims(ptyphims) Calculate Euclidean four-vectors from transverse momentum, rapidity, azimuthal angle, and (optionally) mass for each input. Arguments ptyphims : numpy.ndarray or list An array with shape (M,4) of [pT,y,phi,m] for each particle. An array with shape (M,3) is also accepted where the masses are taken to be zero. A single particle is also accepted. Returns numpy.ndarray An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. If a single particle was given as input, a single four-vector will be returned.","title":"p4s_from_ptyphims"},{"location":"docs/utils/#p4s_from_ptyphis","text":"energyflow.p4s_from_ptyphis(ptyphis) Legacy function : Will be removed in version 1.0. Use p4s_from_ptyphims for equivalent functionality.","title":"p4s_from_ptyphis"},{"location":"docs/utils/#ptyphims_from_p4s","text":"energyflow.ptyphims_from_p4s(p4s, phi_ref=None, keep_allzeros=True) Compute the [pt,y,phi,m] representation of a four-vector for each Euclidean four-vector given as input. All-zero four-vectors are removed unless keep_shape is True . Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. phi_ref : float A reference value used so that all phis will be within $\\pm\\pi$ of this value. A value of None means that no phi fixing will be applied. keep_allzeros : bool Flag to determine if all-zero four-vectors will be retained as such. Otherwise, they are removed (resulting in a change in the shape of the output). Returns numpy.ndarray An array of size (M,4) consisting of the transverse momentum, rapidity, azimuthal angle, and mass of each particle. If a single particle was given as input, a one-dimensional array is returned.","title":"ptyphims_from_p4s"},{"location":"docs/utils/#pts_from_p4s","text":"energyflow.pts_from_p4s(p4s) Calculate the transverse momenta of a collection of four-vectors Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. Returns numpy.ndarray An M -length array consisting of the transverse momentum of each particle. If a single particle was given as input, a single float is returned.","title":"pts_from_p4s"},{"location":"docs/utils/#ys_from_p4s","text":"energyflow.ys_from_p4s(p4s) Calculate the rapidities of a collection of four-vectors Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. Returns numpy.ndarray An M -length array consisting of the rapidity of each particle. If a single particle was given as input, a single float is returned.","title":"ys_from_p4s"},{"location":"docs/utils/#phis_from_p4s","text":"energyflow.phis_from_p4s(p4s, phi_ref=None) Calculate the azimuthal angles of a collection of four-vectors. If phi_ref is not None , then phi_fix is called using this value. Otherwise, the angles are chosen to be in the inverval $[0,2\\pi]$. Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. phi_ref : float See phi_fix Returns numpy.ndarray An M -length array consisting of the azimuthal angle of each particle. If a single particle was given as input, a single float is returned.","title":"phis_from_p4s"},{"location":"docs/utils/#ms_from_p4s","text":"energyflow.ms_from_p4s(p4s) Calculate the masses of a collection of four-vectors. Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. Returns numpy.ndarray An M -length array consisting of the mass of each particle. If a single particle was given as input, a single float is returned.","title":"ms_from_p4s"},{"location":"docs/utils/#phi_fix","text":"energyflow.phi_fix(phis, phi_ref, copy=False) A function to ensure that all phi values are within $\\pi$ of phi_ref . It is assumed that all starting phi values are within $2\\pi$ of phi_ref . Arguments phis : numpy.ndarray or list One-dimensional array of phi values. phi_ref : float A reference value used so that all phis will be within $\\pm\\pi$ of this value. copy : bool Determines if phis are copied or not. If False then phis may be modified in place. Returns numpy.ndarray An array of the fixed phi values.","title":"phi_fix"},{"location":"docs/utils/#flat_metric","text":"energyflow.flat_metric(dim) The Minkowski metric in dim spacetime dimensions in the mostly-minus convention. Arguments dim : int The number of spacetime dimensions (thought to be four in our universe). Returns 1-d numpy.ndarray A dim -length, one-dimensional (not matrix) array equal to [+1,-1,...,-1]","title":"flat_metric"},{"location":"docs/utils/#random-events","text":"Functions to generate random sets of four-vectors. Includes an implementation of the RAMBO algorithm for sampling uniform M-body massless phase space. Also includes other functions for various random, non-center of momentum, and non-uniform sampling.","title":"Random Events"},{"location":"docs/utils/#gen_random_events","text":"energyflow.gen_random_events(nevents, nparticles, dim=4, mass=0) Generate random events with a given number of particles of a given mass in a given spacetime dimension. The spatial components of the momenta are distributed uniformly in $[-1,+1]$. These events are not guaranteed to uniformly sample phase space. Arguments nevents : int Number of events to generate. nparticles : int Number of particles in each event. dim : int Number of spacetime dimensions. mass : float Mass of the particles to generate. Returns numpy.ndarray An (nevents,nparticles,dim) array of events. The particles are specified as [E,p1,p2,...] .","title":"gen_random_events"},{"location":"docs/utils/#gen_random_events_mcom","text":"energyflow.gen_random_events_mcom(nevents, nparticles, dim=4) Generate random events with a given number of massless particles in a given spacetime dimension. The total energy and momentum are made to sum to zero by making about half of the particles incoming. These events are not guaranteed to uniformly sample phase space. Arguments nevents : int Number of events to generate. nparticles : int Number of particles in each event. dim : int Number of spacetime dimensions. Returns numpy.ndarray An (nevents,nparticles,dim) array of events. The particles are specified as [E,p1,p2,...] .","title":"gen_random_events_mcom"},{"location":"docs/utils/#gen_massless_phase_space","text":"energyflow.gen_massless_phase_space(nevents, nparticles, energy=1) Implementation of the RAMBO algorithm for uniformly sampling massless M-body phase space for any center of mass energy. Arguments nevents : int Number of events to generate. nparticles : int Number of particles in each event. energy : float Total center of mass energy of each event. Returns numpy.ndarray An (nevents,nparticles,4) array of events. The particles are specified as [E,p_x,p_y,p_z] .","title":"gen_massless_phase_space"},{"location":"docs/utils/#data-tools","text":"Functions for dealing with datasets. These are not importable from the top level energyflow module, but must instead be imported from energyflow.utils .","title":"Data Tools"},{"location":"docs/utils/#get_examples","text":"energyflow.utils.get_examples(path='~/.energyflow', which='all', overwrite=False) Pulls examples from GitHub. To ensure availability of all examples update EnergyFlow to the latest version. Arguments path : str The destination for the downloaded files. which : { list , 'all' } List of examples to download, or the string 'all' in which case all the available examples are downloaded. overwrite : bool Whether to overwrite existing files or not.","title":"get_examples"},{"location":"docs/utils/#data_split","text":"energyflow.utils.data_split(*args, train=-1, val=0.0, test=0.1, shuffle=True) A function to split a dataset into train, test, and optionally validation datasets. Arguments *args : arbitrary numpy.ndarray datasets An arbitrary number of datasets, each required to have the same number of elements, as numpy arrays. train : { int , float } If a float, the fraction of elements to include in the training set. If an integer, the number of elements to include in the training set. The value -1 is special and means include the remaining part of the dataset in the training dataset after the test and (optionally) val parts have been removed val : { int , float } If a float, the fraction of elements to include in the validation set. If an integer, the number of elements to include in the validation set. The value 0 is special and means do not form a validation set. test : { int , float } If a float, the fraction of elements to include in the test set. If an integer, the number of elements to include in the test set. shuffle : bool A flag to control whether the dataset is shuffle prior to being split into parts. Returns list A list of the split datasets in train, [val], test order. If datasets X , Y , and Z were given as args (and assuming a non-zero val ), then [ X_train , X_val , X_test , Y_train , Y_val , Y_test , Z_train , Z_val , Z_test ] will be returned.","title":"data_split"},{"location":"docs/utils/#to_categorical","text":"energyflow.utils.to_categorical(labels, num_classes=None) One-hot encodes class labels. Arguments labels : 1-d numpy.ndarray Labels in the range [0,num_classes) . num_classes : { int , None } The total number of classes. If None , taken to be the maximum label plus one. Returns 2-d numpy.ndarray The one-hot encoded labels.","title":"to_categorical"},{"location":"docs/utils/#remap_pids","text":"energyflow.utils.remap_pids(events, pid_i=3) Remaps PDG id numbers to small floats for use in a neural network. events are modified in place and nothing is returned. Arguments events : 3-d numpy.ndarray The events as an array of arrays of particles. pid_i : int The index corresponding to pid information along the last axis of events .","title":"remap_pids"},{"location":"docs/utils/#image-tools","text":"Functions for dealing with image representations of events. These are not importable from the top level energyflow module, but must instead be imported from energyflow.utils .","title":"Image Tools"},{"location":"docs/utils/#pixelate","text":"energyflow.utils.pixelate(jet, npix=33, img_width=0.8, nb_chan=1, norm=True, charged_counts_only=False) A function for creating a jet image from an array of particles. Arguments jet : numpy.ndarray An array of particles where each particle is of the form [pt,y,phi,pid] where the particle id column is only used if nb_chan=2 and charged_counts_only=True . npix : int The number of pixels on one edge of the jet image, which is taken to be a square. img_width : float The size of one edge of the jet image in the rapidity-azimuth plane. nb_chan : { 1 , 2 } The number of channels in the jet image. If 1 , then only a $p_T$ channel is constructed (grayscale). If 2 , then both a $p_T$ channel and a count channel are formed (color). norm : bool Whether to normalize the $p_T$ pixels to sum to 1 . charged_counts_only : bool If making a count channel, whether to only include charged particles. Requires that pid information be given. Returns 3-d numpy.ndarray The jet image as a (nb_chan, npix, npix) array.","title":"pixelate"},{"location":"docs/utils/#standardize","text":"energyflow.utils.standardize(*args, channels=None, copy=False, reg=10**-10) Normalizes each argument by the standard deviation of the pixels in arg[0]. The expected use case would be standardize(X_train, X_val, X_test) . Arguments *args : arbitrary numpy.ndarray datasets An arbitrary number of datasets, each required to have the same shape in all but the first axis. channels : int A list of which channels (assumed to be the second axis) to standardize. None is interpretted to mean every channel. copy : bool Whether or not to copy the input arrays before modifying them. reg : float Small parameter used to avoid dividing by zero. It's important that this be kept consistent for images used with a given model. Returns list A list of the now-standardized arguments.","title":"standardize"},{"location":"docs/utils/#zero_center","text":"energyflow.utils.zero_center(args, kwargs) Subtracts the mean of arg[0] from the arguments. The expected use case would be standardize(X_train, X_val, X_test) . Arguments *args : arbitrary numpy.ndarray datasets An arbitrary number of datasets, each required to have the same shape in all but the first axis. channels : int A list of which channels (assumed to be the second axis) to zero center. None is interpretted to mean every channel. copy : bool Whether or not to copy the input arrays before modifying them. Returns list A list of the zero-centered arguments.","title":"zero_center"}]}